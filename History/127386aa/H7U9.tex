\documentclass[12pt]{article}
\usepackage{amsthm,amssymb,amsfonts,amsmath,amstext}

\marginparwidth 0pt
\oddsidemargin -1 truecm
\evensidemargin  0pt
\marginparsep 0pt
\topmargin -2.8truecm
\linespread{1.5}
\textheight 25.7 truecm
\textwidth 18.4 truecm
\newenvironment{remark}{\noindent{\bf Remark }}{\vspace{0mm}}
\newenvironment{remarks}{\noindent{\bf Remarks }}{\vspace{0mm}}
\newenvironment{question}{\noindent{\bf Question }}{\vspace{0mm}}
\newenvironment{questions}{\noindent{\bf Questions }}{\vspace{0mm}}
\newenvironment{note}{\noindent{\bf Note }}{\vspace{0mm}}
\newenvironment{summary}{\noindent{\bf Summary }}{\vspace{0mm}}
\newenvironment{back}{\noindent{\bf Background}}{\vspace{0mm}}
\newenvironment{conclude}{\noindent{\bf Conclusion}}{\vspace{0mm}}
\newenvironment{concludes}{\noindent{\bf Conclusions}}{\vspace{0mm}}
\newenvironment{dill}{\noindent{\bf Description of Dill's model}}{\vspace{0mm}}
\newenvironment{maths}{\noindent{\bf Mathematics needed}}{\vspace{0mm}}
\newenvironment{object}{\noindent{\bf Objective}}{\vspace{0mm}}
\newenvironment{notes}{\noindent{\bf Notes }}{\vspace{0mm}}
\newenvironment{theorem}{\noindent{\bf Theorem }}{\vspace{0mm}}
\newenvironment{example}{\noindent{\bf Example }}{\vspace{0mm}}
\newenvironment{examples}{\noindent{\bf Examples }}{\vspace{0mm}}
\newenvironment{lemma}{\noindent{\bf Lemma }}{\vspace{0mm}}
\newenvironment{solution}{\noindent{\it Solution}}{\vspace{2mm}}
\newcommand{\QED}{\fbox{}}
\newcommand{\ds}{\displaystyle}
\newcommand{\bs}{\boldsymbol}

\usepackage{graphicx}
\graphicspath{{converted_graphics/}}
\begin{document}

\baselineskip 18 pt

cc3403

\newpage

\noindent {\bf \underline{Question 1} (40 points)}

\vspace{0.35cm}

\noindent A study was conducted to study the amount of converted sugar in a certain process at various temperatures. The data were coded and recorded as follows.
\begin{center}
\begin{tabular}{|ccc|ccc|} \hline
& {\sf Temperature $x_i$} & & & {\sf Converted Sugar $y_i$} & \\ \hline\hline
& $1.0$ & & & $8.1$ & \\
& $1.1$ & & & $7.8$ & \\
& $1.2$ & & & $8.5$ & \\
& $1.3$ & & & $9.8$ & \\
& $1.4$ & & & $9.5$ & \\
& $1.5$ & & & $8.9$ & \\
& $1.6$ & & & $8.6$ & \\
& $1.7$ & & & $10.2$ & \\
& $1.8$ & & & $9.3$ & \\
& $1.9$ & & & $9.2$ & \\
& $2.0$ & & & $10.5$ & \\ \hline
\end{tabular}
\end{center}
\noindent A simple linear regression model
$$
\Omega: y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, \ \ \, i = 1, 2, \dots, 11,
$$
where $\beta_0$ and $\beta_1$ are unknown parameters, is fitted to these data.
\begin{enumerate}
\item[(a)]
({\em 4 points\/})~State {\em two\/} assumptions of the above model.
\item[(b)]
({\em 4 points\/})~Find the equation of the estimated regression line and interpret the meaning of its slope.
\item[(c)]
({\em 4 points\/})~Determine the coefficient of determination and interpret its meaning.
\item[(d)]
({\em 6 points\/})~Find an unbiased point estimate for the error variance $\sigma^2$ of the above model.
\item[(e)]
({\em 6 points\/})~Test, at the $1\%$ level of significance, the hypothesis that the slope of the actual regression line is different from two.
\item[(f)]
\begin{enumerate}
\item[(i)]
({\em 7 points\/})~Use the analysis-of-variance (ANOVA) approach to test for the existence of a linear relationship between temperature and the amount of converted sugar. Test at $\alpha = 0.05$.
\item[(ii)]
({\em 3 points\/})~Can this approach be used to test for the existence of a positive linear relationship between the two variables? Explain your answer.
\end{enumerate}
\item[(g)]
({\em 6 points\/})~Construct a $95\%$ prediction interval for the amount of converted sugar corresponding to the (coded) temperature $1.6$.
\end{enumerate}

\newpage

\noindent {\bf \underline{Question 2} (48 points)}

\begin{enumerate}
\item[(a)]
Consider a multiple linear regression model
$$
\bs{Y} = X\bs{\beta} + \bs{\varepsilon}, \ \ \, \bs{\varepsilon} \sim {\rm N}_n\left({\bs 0}, \sigma^2 I_n\right),
$$
where $X$ is an $n \times p$ design matrix, $\bs{Y}$ is a vector of $n$ independent response variables, $\bs{\beta}$ is a constant vector of the regression parameters and $I_n$ denotes the $n \times n$ identity matrix. The parameter $\sigma^2$ is unknown.

Let $\ds \widehat{\bs{\beta}}$ be the least squares estimator for $\bs{\beta}$. Show that
\begin{enumerate}
\item[(i)]
({\em 4 points\/})~$\ds E\left(\widehat{\bs{\beta}}\right) = \bs{\beta}$.
\item[(ii)]
({\em 6 points\/})~$\ds {\rm Var}\left(\widehat{\bs{\beta}}\right) = \sigma^2 \left(X^T X\right)^{-1}$.
\end{enumerate}
\item[(b)]
A multiple linear regression model
$$
\Omega : E\left(Y\right) = \beta_0 + \beta_1 x_{1} + \beta_2 x_{2},
$$
where $\beta_0$, $\beta_1$ and $\beta_2$ are unknown parameters, is suggested to fit the following data.
\begin{center}
\begin{tabular}{|c||cccccccc|} \hline
$x_1$ & $2$ & $0$ & $-2$ & $1$ & $-1$ & $3$ & $2$ & $-1$ \\ \hline
$x_2$ & $-3$ & $-2$ & $-1$ & $0$ & $0$ & $1$ & $2$ & $3$ \\ \hline
$y$ & $2.8$ & $1.0$ & $4.2$ & $3.8$ & $3.6$ & $2.0$ & $3.0$ & $6.4$ \\ \hline
\end{tabular}
\end{center}
\begin{enumerate}
\item[(i)]
({\em 2 points\/})~Write down the design matrix of the model $\Omega$.
\item[(ii)]
({\em 8 points\/})~Find the least squares estimates for $\beta_0$, $\beta_1$ and $\beta_2$.
\item[(iii)]
({\em 6 points\/})~Calculate the standard error of estimate of the above model ({\sf Hint: You may use the fact that $\ds \sum_{i = 1}^{8} y_i^2 = 107.84$ {\em without\/} proof}).
\item[(iv)]
({\em 4 points\/})~Find the adjusted coefficient of multiple determination of the above model.
\item[(v)]
Test, at the $5\%$ level of significance, for
\begin{enumerate}
\item[(1)]
({\em 6 points\/})~significance of the model $\Omega$.
\item[(2)]
({\em 6 points\/})~significance of the predictor variable $x_2$ in the model $\Omega$.
\end{enumerate}
\item[(vi)]
({\em 6 points\/})~Another model $\Omega' : E\left(Y\right) = \alpha_0 + \alpha_1 x_{1} + \alpha_2 x_{2} + \alpha_3 x_1 x_2$ is proposed to fit the given data. It is given that
$$
{\rm SSE}\left(\Omega'\right) \approx 3.4230352
$$
(you are {\em not\/} required to verify this fact). Use a partial $F$-test at $\alpha = 0.01$ to determine which model, $\Omega$ or $\Omega'$, is better.
\end{enumerate}
\end{enumerate}

\newpage

\noindent {\bf \underline{Question 3} (12 points)}

\vspace{0.35cm}

\noindent Consider the following data set with repeated observations.

\begin{center}
\begin{tabular}{|c||cc|cc|ccc|cc|ccc|} \hline
$x$ & $2.0$ & $2.0$ & $3.7$ & $3.7$ & $4.0$ & $4.0$ & $4.0$ & $4.7$ & $4.7$ & $5.3$ & $5.3$ & $5.3$ \\ \hline
$y$ & $2.8$ & $1.5$ & $3.7$ & $1.7$ & $2.8$ & $2.8$ & $2.2$ & $3.2$ & $1.9$ & $3.5$ & $2.8$ & $2.1$ \\ \hline
\end{tabular}
\end{center}

\begin{enumerate}
\item[(a)]
({\em 3 points\/})~Calculate the sum of squares due to pure error (SSPE).
\item[(b)]
({\em 9 points\/})~By carrying out a lack of fit test at the $5\%$ level of significance, determine whether or not a simple linear regression model is adequate for explaining the observations.
\end{enumerate}


\newpage

\begin{center}
\underline{\bf Useful Formulae for Reference}
\end{center}

\begin{enumerate}
\item[1.]
{\bf Simple Linear Regression}
\begin{enumerate}
\item[(a)]
A $100(1 - \alpha)\%$ confidence interval for $\beta_0$
$$
\widehat{\beta_0} \pm t_{\frac{\alpha}{2};\,n - 2}\sqrt{\frac{{\rm MSE}\sum x_i^2}{nS_{xx}}}
$$
\item[(b)]
A $100(1 - \alpha)\%$ confidence interval for $\beta_1$
$$
\widehat{\beta_1} \pm t_{\frac{\alpha}{2};\,n - 2}\sqrt{\frac{{\rm MSE}}{S_{xx}}}
$$
\item[(c)]
Test statistic for $\beta_0$
$$
\frac{\widehat{\beta_0} - c}{\sqrt{\frac{{\rm MSE}\sum x_i^2}{nS_{xx}}}}
$$
\item[(d)]
Test statistic for $\beta_1$
$$
\frac{\widehat{\beta_1} - c}{\sqrt{\frac{{\rm MSE}}{S_{xx}}}}
$$
\item[(e)]
A $100(1 - \alpha)\%$ confidence interval for $E(Y_0)$ when $X = x_0$
$$
\widehat{\beta_0} + \widehat{\beta_1}x_0 \pm t_{\frac{\alpha}{2};\,n - 2}\sqrt{{\rm MSE}\left[\frac{1}{n} + \frac{\left(x_0 - \overline{x}\right)^2}{S_{xx}}\right]}
$$
\item[(f)]
A $100(1 - \alpha)\%$ prediction interval for $Y_0$ when $X = x_0$
$$
\widehat{\beta_0} + \widehat{\beta_1}x_0 \pm t_{\frac{\alpha}{2};\,n - 2}\sqrt{{\rm MSE}\left[1 + \frac{1}{n} + \frac{\left(x_0 - \overline{x}\right)^2}{S_{xx}}\right]}
$$
\end{enumerate}
\item[2.]
{\bf Multiple Linear Regression}
\begin{enumerate}
\item[(a)]
A $100(1 - \alpha)\%$ confidence interval for $\beta_j$
$$
\widehat{\beta_j} \pm t_{\frac{\alpha}{2};\,n - p}\sqrt{{\rm MSE} \cdot a_{j + 1,\,j + 1}}
$$
\item[(b)]
Test statistic for $\beta_j$
$$
\frac{\widehat{\beta_j} - c}{\sqrt{{\rm MSE} \cdot a_{j + 1,\,j + 1}}}
$$
\item[(c)]
A $100(1 - \alpha)\%$ confidence interval for $E(Y_0)$ when ${\bs x} = {\bs x_0}$
$$
{\bs x_0}^T\widehat{\bs{\beta}} \pm t_{\frac{\alpha}{2};\,n - p}\sqrt{{\rm MSE} \cdot {\bs x_0}^T\left(X^T X\right)^{-1}{\bs x_0}}
$$
\item[(d)]
A $100(1 - \alpha)\%$ prediction interval for $Y_0$ when ${\bs x} = {\bs x_0}$
$$
{\bs x_0}^T\widehat{\bs{\beta}} \pm t_{\frac{\alpha}{2};\,n - p}\sqrt{{\rm MSE}\left[1 + {\bs x_0}^T\left(X^T X\right)^{-1}{\bs x_0}\right]}
$$
\end{enumerate}
\end{enumerate}

\newpage

\vspace{0.8cm}

\centerline{\includegraphics[width=18.5cm,height=25cm,keepaspectratio]{table2}}

\newpage

\vspace{3.5cm}

\centerline{\includegraphics[width=17.5cm,height=24.8cm,keepaspectratio]{table3a}}

\newpage

\vspace{3.5cm}

\centerline{\includegraphics[width=17.5cm,height=24.8cm,keepaspectratio]{table3b}}

\newpage

\centerline{\includegraphics[width=19.6cm,height=24.5cm,keepaspectratio]{table4}}

\begin{center}
{\bf \large  End of Paper}
\end{center}




















\end{document} 