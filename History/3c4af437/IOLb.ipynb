{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfb2030",
   "metadata": {},
   "source": [
    "# reminder\n",
    "- offset (initial margin) (add something)\n",
    "- age, gender, \n",
    "- build an initial model based on age, gender, etc\n",
    "    - can add weight and height, but as a quadratic \n",
    "    - e.g., GLM\n",
    "- add the output of the initial model as a feature to the dlr\n",
    "    - as an offset, not as a feature (offset is a parameter?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91806e66",
   "metadata": {},
   "source": [
    "# loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b39467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "sys.path.append(\"./ds_utils\") # for reading self-de fined modules\n",
    "from ds_utils.ds_preamble import *  # # self-defined module\n",
    "from ds_utils.ds_helper import *  # self-defined module\n",
    "from ds_utils.ds_plotting import *  # # self-defined module\n",
    "from math import ceil \n",
    "# from smart_open import open \n",
    "\n",
    "import dsar # custom library to read data from cloud\n",
    "\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.precision', 5)\n",
    "\n",
    "\n",
    "timestamp = get_timestamp() # this timestamp will be appended to many output files\n",
    "random_state=1234567 # used to make results reproducible\n",
    "\n",
    "use_expo_less_than_thresh = False\n",
    "bmi_offset = True\n",
    "# bmi_offset = False\n",
    "\n",
    "# cohort_include_smoker=False\n",
    "# formulation_name ='f2'\n",
    "# use_adj_premium = True\n",
    "# use_inflate=False\n",
    "\n",
    "# remap_model = {'score_lr_xgb': 'dlr'}\n",
    "remap_model = False\n",
    "\n",
    "# ------------------------------- refit using R ------------------------------ #\n",
    "# lr_out = 'refit_hb_lr_output_20220714_163622' # SELECT * FROM temp.refit_hb_lr_output_20220714_163622\n",
    "# lr_out = 'refit_hb_lr_output_sim_m238'\n",
    "# pred_col_names = ['score_lr_xgb']\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# ------------------------ important variations to run ----------------------- #\n",
    "# lr_out = 'hb_lr_output_20220714_163622' # with weight height, n_estimator = 20\n",
    "# lr_out = 'hb_lr_output_20220715_114029' # no weight height, n_estimator = 120\n",
    "# lr_out = 'hb_lr_output_20220726_154536' # keep app_age>=6; no weight height\n",
    "# lr_out = 'hb_lr_output_20220726_173905' # keep app_age>=6; with weight height\n",
    "# lr_out = 'hb_lr_output_20220727_135834' # keep app_age>=18; no weight height\n",
    "# lr_out = 'hb_lr_output_20220727_135726' # keep app_age>=18; with weight height\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# ---------------------- old format, before final report --------------------- #\n",
    "# lr_out = 'hb_lr_output_comb_allyr_loss_ratio_20220525_162627'\n",
    "# pred_col_names = ['xgb', 'freq_severity', 'cla_reg']\n",
    "\n",
    "# -------------------------------- new format -------------------------------- #\n",
    "\n",
    "# ------------------------ with test data in train set ----------------------- #\n",
    "# lr_out = 'hb_lr_output_20220715_114029' # no weight height, n_estimator = 120\n",
    "# lr_out = 'hb_lr_output_20220714_163400' # no weight height, n_estimator = 150\n",
    "# lr_out = 'hb_lr_output_20220714_163622' # with weight height, n_estimator = 20\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "# ------------------------------ filter app_age ------------------------------ #\n",
    "# lr_out = 'hb_lr_output_20220726_154536' # keep app_age>=6; no weight height\n",
    "# lr_out = 'hb_lr_output_20220726_173905' # keep app_age>=6; with weight height\n",
    "# lr_out = 'hb_lr_output_20220726_154339' # keep app_age>=6; with weight height; filter weight by of all ages\n",
    "# lr_out = 'hb_lr_output_20220727_135834' # keep app_age>=18; no weight height\n",
    "# lr_out = 'hb_lr_output_20220727_135726' # keep app_age>=18; with weight height\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------ filter weight, height, bmi ------------------------ #\n",
    "# lr_out = 'hb_lr_output_20220725_144238' # filter all app_ages. with weight height as features.\n",
    "# lr_out = 'hb_lr_output_20220725_144055' # filter app_ages<=5 only. no weight height as features.\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# --------------- adjustment in bmi for age<=1, by bmi=bmi_clip -------------- #\n",
    "# lr_out = 'hb_lr_output_20220719_114540' # weight height; n_estimator=120; test data in train; adjustment in bmi for age <= 1. result not as good\n",
    "# lr_out = 'hb_lr_output_20220719_114421' # no weight height; n_estimator=120; test data in train; adjustment in bmi for age <= 1. result bad\n",
    "# lr_out = 'hb_lr_output_20220719_114223' # no weight height; n_estimator=120; no test data in train; adjustment in bmi for age <= 1\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# ---------------- adjustment in bmi for age<=1, by bmi=median --------------- #\n",
    "# lr_out = 'hb_lr_output_20220722_113524' # no weight height; n_estimator=120\n",
    "# lr_out = 'hb_lr_output_20220722_113745' # with weight height; n_estimator=20\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "\n",
    "# lr_out = 'hb_lr_output_20220721_101325' # no weight height, use rv3. n_estimator=120. This version is for debugging purposes.\n",
    "\n",
    "# use weight and height\n",
    "# lr_out = 'hb_lr_output_20220705_104026' # with higher lower bound for max_depth, n_estimator. Use weight and height. overfit. result ok. low decline in prefer\n",
    "# lr_out = 'hb_lr_output_20220706_122409' # use `weight` and `height` as well. No change in `n_estimator` and `max_depth`. result good. This variation thinks occupation risk is important\n",
    "\n",
    "# no change in weight and height\n",
    "# lr_out = 'hb_lr_output_20220706_122621' # with higher lower bound for n_estimator, and lower bound for max_depth is 4. result not good. high decline in prefer\n",
    "# lr_out = 'hb_lr_output_20220706_122536' # with higher lower bound for n_estimator only. lower bound is 120. result good. This variation thinks occupation risk not important\n",
    "# lr_out = 'hb_lr_output_20220707_135752' # with higher lower bound for n_estimator only. lower bound is 200. not as good\n",
    "\n",
    "# lr_out = 'hb_lr_output_20220704_153632' # with higher lower bound for max_depth, n_estimator. lower bound for max_depth is 7. result not good. overfit.\n",
    "\n",
    "# lr_out = 'hb_lr_output_20220622_153846' # adj_bmi = 3\n",
    "# lr_out = 'hb_lr_output_20220622_154333' # adj_bmi = 2\n",
    "\n",
    "# lr_out = 'hb_lr_output_20220630_120625' # like 20220622_154333. Just to make sure after updating the code, the models are unaffected. with dlr only. no use\n",
    "# lr_out = 'hb_lr_output_20220630_112716' # like 20220622_154333. Just to make sure after updating the code, the models are unaffected\n",
    "\n",
    "# lr_out = 'hb_lr_output_20220630_180326' # adj_bmi=1\n",
    "# lr_out = 'hb_lr_output_20220701_060425' # no adj_bmi, no weight, height, bmi\n",
    "\n",
    "pred_col_names = ['dlr', 'freq_sev', 'cla_reg']\n",
    "# pred_col_names = ['dlr']\n",
    "# ---------------------------------------------------------------------------- #\n",
    "\n",
    "cohort_col = ['age_gp','sex_male']\n",
    "bin_chosen_pred_col_name = f\"bin_{pred_col_names[0]}\"\n",
    "chosen_pred_col_name = pred_col_names[0]\n",
    "\n",
    "n_bins = 100 # if n_bins = 100, then do percentile\n",
    "\n",
    "tables = {\n",
    "    'lr_table': ('hb', 'hb_poc_premiums_rv3'),\n",
    "    'lr_out': ('temp', lr_out),\n",
    "    'res_out': ('temp', '_'.join(['f2_thresh', 'lr', re.search('\\d+_\\d+', lr_out)[0], timestamp ])),\n",
    "    # 'res_out': ('temp', ('_'.join(['f2_thresh', 'lr', re.search('\\d+_\\d+', lr_out)[0], timestamp]) + ('_offset' if bmi_offset else ''))),\n",
    "    'res_out_offset': ('temp', ('_'.join(['f2_thresh', 'lr', 'offset', re.search('\\d+_\\d+', lr_out)[0],  timestamp]) )),\n",
    "    'split'   : ('temp', 'hb_poc_splits'),\n",
    "    \n",
    "    # 'res_out_no_ts':('temp', ('_'.join(['f2_thresh', 'lr', re.search('\\d+_\\d+', lr_out)[0]]) + ('_offset' if bmi_offset else ''))),\n",
    "    # 'res_out': ('temp', '_'.join(['thresh',lr_out, timestamp])),\n",
    "    # 'res_out': ('temp', '_'.join(['thresh',lr_out])),\n",
    "}\n",
    "\n",
    "print(tables)\n",
    "\n",
    "output_path = Path('thresh_output')\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open('_timestamp.txt', 'x') as f:\n",
    "        f.write(f\"{timestamp}\\n\")\n",
    "        # f.write(f\"\\n{tables['res_out'][1]}\")\n",
    "        f.write('_'.join(['f2_thresh', 'lr', re.search('\\d+_\\d+', lr_out)[0]]))\n",
    "except FileExistsError:\n",
    "    print('file _timestamp.txt already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ce601",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_'.join(['f2_thresh', 'lr', re.search('\\d+_\\d+', lr_out)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables['res_out_offset']\n",
    "tables['res_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables\n",
    "# table = '_'.join([table, timestamp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b0c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for auto-reloading the self-defined modules if they have any changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_records(df):\n",
    "    # return a new df\n",
    "    df_original = df.sort_values(['contract_no','year_seq'])\n",
    "\n",
    "    # specify which columns need to be aggregated, and the corresponding aggregate function\n",
    "    col_to_agg = {\n",
    "        'exposure':'sum',\n",
    "        # 'tot_pay_amt': lambda g: g.sum(min_count=1),\n",
    "        'tot_pay_amt': 'sum',\n",
    "        'eff_annual_prem':'sum',\n",
    "        }\n",
    "    \n",
    "    df_by_contracts_agg = (\n",
    "        df_original\n",
    "        .groupby('contract_no')\n",
    "        .agg(col_to_agg)\n",
    "        .assign(\n",
    "            loss_ratio = lambda df: df['tot_pay_amt']/df['eff_annual_prem'],\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return (\n",
    "        df_original\n",
    "        # .drop_duplicates('contract_no', keep='last')\n",
    "        .drop_duplicates('contract_no', keep='first')\n",
    "        .drop(list(col_to_agg.keys()), axis=1, errors='ignore')\n",
    "        .merge(df_by_contracts_agg, on='contract_no')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e4579",
   "metadata": {},
   "source": [
    "# data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_cols = [\n",
    "    'contract_no',\n",
    "    'annual_prem',\n",
    "    'adj_annual_prem',\n",
    "    'exposure',\n",
    "    'year_seq',\n",
    "    'tot_pay_amt',\n",
    "    'inflate_tot_pay_amt',\n",
    "    'bmi',\n",
    "    'diff_low',\n",
    "    'diff_high',\n",
    "    'bmi_clip',\n",
    "    'first_pol_substandard',\n",
    "    'risk_class',\n",
    "    'ins_sex',\n",
    "    'app_age',\n",
    "    'clean_record'\n",
    "    \n",
    "]\n",
    "\n",
    "age_gp_interval = list(range(0, 56, 5)) + [np.inf]\n",
    "\n",
    "# cols needed from lr model dataset\n",
    "cols_table = ', '.join(f'lr_table.{col}' for col in useful_cols)\n",
    "# cols needed from lr output dataset\n",
    "# cols_out = ', '.join(f'lr_out.{col}' for col in ['clean_record'] + pred_col_names)\n",
    "cols_out = ', '.join(f'lr_out.{col}' for col in pred_col_names)\n",
    "\n",
    "# df_lr_out = load_table(*tables['lr_out'], columns=['contract_no', 'clean_record'] + pred_col_names)\n",
    "# # df_lr_out = load_table(*tables['lr_out'], columns=['contract_no', 'clean_record','substandard'] + pred_col_names)\n",
    "# # df_info = load_table(*tables['lr_table'], columns=useful_cols, where='year_seq<=5')\n",
    "# # split = load_table(*tables['split'], columns=['contract_no', 'train_1']) \n",
    "\n",
    "q = f\"\"\"\n",
    "SELECT {cols_table}, s.train_1, {cols_out}\n",
    "FROM \n",
    "    {'.'.join(tables['lr_table'])} lr_table \n",
    "\tJOIN {'.'.join(tables['split'])} s USING (contract_no) \n",
    "\tJOIN {'.'.join(tables['lr_out'])} lr_out USING (contract_no)\n",
    "WHERE lr_table.year_seq <= 5\n",
    "\"\"\"\n",
    "\n",
    "with dsar.psql_con(\"WRITE\") as con:\n",
    "    df_info = pd.read_sql(q, con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c344c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info[['adj_annual_prem', 'exposure']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76982686",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_out = (\n",
    "    df_info\n",
    "    .assign(\n",
    "        eff_annual_prem=lambda df: df.adj_annual_prem * df.exposure,\n",
    "        age_gp=lambda df: pd.cut(df['app_age'], age_gp_interval, right=True, include_lowest=True)\n",
    "        )\n",
    "    .pipe(combine_records)\n",
    "    .query(\n",
    "        \"risk_class == 'decline' or train_1 == 1 or (train_1==0 and exposure == 5)\" \n",
    "        if use_expo_less_than_thresh \n",
    "        else \"risk_class == 'decline' or exposure == 5\"\n",
    "        )\n",
    "    # .query(\"risk_class == 'decline' or exposure == 5\")\n",
    "    .replace({\n",
    "            'ins_sex': {'M':1, 'F':0},\n",
    "            'risk_class': {\n",
    "                'exclusion':'substandard', \n",
    "                'exclusion_loading': 'substandard', \n",
    "                'loading':'substandard'\n",
    "                },\n",
    "            })\n",
    "    .rename({\n",
    "        'ins_sex':'sex_male', \n",
    "        'first_pol_substandard': 'substandard', \n",
    "        'xgb': 'dlr',\n",
    "        'freq_severity': 'freq_sev',\n",
    "        }, axis=1\n",
    "        )\n",
    "    # .merge(df_lr_out, on='contract_no', how='inner')\n",
    "    # .merge(split, on='contract_no', how='inner')\n",
    "    \n",
    ")\n",
    "\n",
    "if remap_model:\n",
    "    lr_out = lr_out.rename(remap_model, axis=1)\n",
    "    pred_col_names = list(remap_model.values())\n",
    "    bin_chosen_pred_col_name = f\"bin_{pred_col_names[0]}\"\n",
    "    chosen_pred_col_name = pred_col_names[0]\n",
    "\n",
    "# this is needed because we don't want to include decline records when calculating aggregate lr \n",
    "lr_out.loc[lr_out.risk_class=='decline', ['tot_pay_amt','eff_annual_prem', 'loss_ratio']] = np.nan\n",
    "\n",
    "lr_out_train = lr_out.query(\"train_1==1\").copy()\n",
    "lr_out_test = lr_out.query(\"train_1==0\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_col_names = ['dlr', 'freq_sev', 'cla_reg']\n",
    "# bin_chosen_pred_col_name = f\"bin_{pred_col_names[0]}\"\n",
    "# chosen_pred_col_name = pred_col_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_out_test.exposure.mean()\n",
    "# lr_out_train.exposure.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ea29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_info.query(\"contract_no =='80000098'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44411402",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = lr_out_test.query(\"risk_class=='standard'\")\n",
    "\n",
    "find_loss_ratio(temp)\n",
    "\n",
    "\n",
    "# temp.tot_pay_amt.sum()/((temp.annual_prem * temp.exposure).sum())\n",
    "\n",
    "temp[['contract_no', 'annual_prem', 'adj_annual_prem', 'exposure', 'eff_annual_prem']]\n",
    "\n",
    "\n",
    "# temp.annual_prem*temp.exposure\n",
    "\n",
    "# temp.eff_annual_prem\n",
    "# temp.adj_annual_prem * temp.exposure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef5a89",
   "metadata": {},
   "source": [
    "## find the bin of each record, according to predicted loss ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_col_name in pred_col_names:\n",
    "    bins = (\n",
    "        lr_out_train\n",
    "        .groupby(cohort_col)[pred_col_name]\n",
    "        # wingho. will create 100 bins\n",
    "        .apply(lambda s: np.quantile(s, q=np.arange(1/n_bins, 1.0, 1/n_bins))) \n",
    "        \n",
    "        # jason. will create 101 bins\n",
    "        # .apply(lambda s: np.percentile(s, q=np.linspace(1,100,100))) \n",
    "    )\n",
    "    \n",
    "    for portion in [lr_out_test, lr_out_train]:\n",
    "        portion[f'bin_{pred_col_name}'] = (\n",
    "            portion\n",
    "            .groupby(cohort_col)[pred_col_name]\n",
    "            # wingho\n",
    "            # .apply(find_rank, quantiles=bins, n_bins=n_bins) \n",
    "            \n",
    "            # wingho. same as above\n",
    "            .apply(lambda s: pd.Series(np.digitize(s, bins[s.name])+1, index=s.index))\n",
    "            \n",
    "            # jason\n",
    "            # .apply(lambda s: pd.Series(\n",
    "            #     np.digitize(s, np.insert(bins[s.name], 0, -1), right=True), index=s.index)\n",
    "            #     )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb723275",
   "metadata": {},
   "source": [
    "# sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_riskclass_size = lr_out_test.risk_class.value_counts_plus(index_name='risk_class')\n",
    "df_riskclass_cohort_size = lr_out_test.groupby(cohort_col).risk_class.pipe(value_counts_plus).unstack(-1)\n",
    "\n",
    "df_riskclass_size\n",
    "df_riskclass_cohort_size\n",
    "\n",
    "df_riskclass_size.to_excel(output_path / \"df_riskclass_size.xlsx\")\n",
    "df_riskclass_cohort_size.to_excel(output_path / \"df_riskclass_cohort_size.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb44fe9",
   "metadata": {},
   "source": [
    "## check app_age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app_age_size = lr_out_test.app_age.value_counts_plus(cum=True, index_name='app_age').sort_index()\n",
    "\n",
    "df_app_age_size\n",
    "\n",
    "df_app_age_size.to_excel(output_path / \"df_app_age_size.xlsx\")\n",
    "\n",
    "df_app_age_size['rate_cum'].plot(xticks=range(0,81,5), xlim=(0,82), xlabel='app_age', ylabel='cumulative rate', yticks=np.arange(0,1.1,0.1), title='cumulative distribution of application age')\n",
    "\n",
    "savefig_plus(output_path/f\"df_app_age_size_{timestamp}.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_out\n",
    "lr_out.query(\"bmi.between(38.54,45)\")\n",
    "# [['contract_no','bmi', 'clean_record','app_age']].sort_values(ascending=False, by='bmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a47a06",
   "metadata": {},
   "source": [
    "## check cohort size, claim count and rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort_size_cnt = lr_out_test.groupby(cohort_col).size().unstack()\n",
    "# cohort_size_rate = lr_out_test.groupby(cohort_col).size().unstack()/len(lr_out_test)\n",
    "# df_cohort_size = pd.concat([cohort_size_cnt, cohort_size_rate], axis=1, keys=['count','rate'])\n",
    "\n",
    "cohort_size_cnt = pd.crosstab(index=lr_out_test['age_gp'], columns=lr_out_test['sex_male'], margins=True)\n",
    "cohort_size_rate = pd.crosstab(index=lr_out_test['age_gp'], columns=lr_out_test['sex_male'], margins=True, normalize=True)\n",
    "df_cohort_size = pd.concat([cohort_size_cnt, cohort_size_rate], axis=1, keys=['record_count','record_count_rate'])\n",
    "\n",
    "df_cohort_size\n",
    "# df_cohort_size.to_excel(output_path/f\"df_cohort_size.xlsx\")\n",
    "\n",
    "lr_out_test_has_claim = lr_out_test.query(\"loss_ratio>0\")\n",
    "cohort_size_claim_cnt = pd.crosstab(index=lr_out_test_has_claim['age_gp'], columns=lr_out_test_has_claim['sex_male'], margins=True)\n",
    "cohort_size_claim_cnt_rate = pd.crosstab(index=lr_out_test_has_claim['age_gp'], columns=lr_out_test_has_claim['sex_male'], margins=True, normalize=True)\n",
    "df_cohort_size_claim = pd.concat([cohort_size_claim_cnt, cohort_size_claim_cnt_rate], axis=1, keys=['claim_count','claim_count_rate'])\n",
    "df_cohort_size_claim\n",
    "\n",
    "df_cohort_size = pd.concat([df_cohort_size, df_cohort_size_claim], axis=1)\n",
    "df_cohort_size\n",
    "df_cohort_size.to_excel(output_path/f\"df_cohort_size.xlsx\")\n",
    "\n",
    "# 10% data in prefer\n",
    "\n",
    "# lr_prefer is obtained from 16x people"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc98451",
   "metadata": {},
   "source": [
    "## check the `risk_class` and `substandard` distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for portion_name, portion in zip(['whole', 'train', 'test'], [lr_out, lr_out_train, lr_out_test]):\n",
    "    print(f\"# ------------------------ for {portion_name} dataset ------------------------ #\")\n",
    "    portion.risk_class.value_counts(dropna=False)\n",
    "    portion.substandard.value_counts(dropna=False)\n",
    "    portion.loss_ratio.mean()\n",
    "    portion.groupby('risk_class').loss_ratio.mean()\n",
    "    print(\"# ------------------------------------ end ----------------------------------- #\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c24813",
   "metadata": {},
   "source": [
    "## check cohort size and unique predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce53790",
   "metadata": {},
   "outputs": [],
   "source": [
    "for portion_name, portion in zip(['train','test'],[lr_out_train, lr_out_test]):\n",
    "    for pred in pred_col_names:\n",
    "        print(f\"n_unqiue output for {pred} on {portion_name} set: {portion[pred].nunique()}\")\n",
    "        \n",
    "# print(\"cohort size:\")\n",
    "df_sizes = pd.concat(\n",
    "    [\n",
    "        lr_out_train.groupby(cohort_col).size().unstack(), \n",
    "        lr_out_test.groupby(cohort_col).size().unstack(),\n",
    "    ], \n",
    "    axis=1, \n",
    "    keys=['train','test'],\n",
    "    )\n",
    "\n",
    "# print(\"unique values:\")\n",
    "df_uniques = pd.concat(\n",
    "    [\n",
    "        lr_out_train.groupby(cohort_col)[chosen_pred_col_name].nunique().unstack(), \n",
    "        lr_out_test.groupby(cohort_col)[chosen_pred_col_name].nunique().unstack(),\n",
    "    ], \n",
    "    axis=1, \n",
    "    keys=['train','test'],\n",
    "    )\n",
    "\n",
    "pd.concat([df_sizes, df_uniques], axis=1, keys=['n_records', 'n_unique'])\n",
    "# pd.concat([df_sizes, df_uniques], axis=1, keys=['n_records', 'n_unique']).to_excel(output_path/f\"n_record_vs_n_unique_{timestamp}.xlsx\")\n",
    "pd.concat([df_sizes, df_uniques], axis=1, keys=['n_records', 'n_unique']).to_csv(output_path/f\"n_record_vs_n_unique_{timestamp}.csv\")\n",
    "\n",
    "\n",
    "print(f\"for {chosen_pred_col_name} model, the frequency distribution of the prediction values is:\")\n",
    "(\n",
    "lr_out_test[chosen_pred_col_name]\n",
    ".value_counts(normalize=True)\n",
    ".reset_index()\n",
    ".rename({'index':'predict', 'dlr':'prop'}, axis=1)\n",
    "[:30]\n",
    ")\n",
    "\n",
    "# lr_out = 'hb_lr_output_20220704_153632'\n",
    "# n_unqiue output for dlr on train set: 28868\n",
    "# n_unqiue output for freq_sev on train set: 52517\n",
    "# n_unqiue output for cla_reg on train set: 36844\n",
    "# n_unqiue output for dlr on test set: 14796\n",
    "# n_unqiue output for freq_sev on test set: 23607\n",
    "# n_unqiue output for cla_reg on test set: 18355\n",
    "\n",
    "\n",
    "# n_unqiue output for dlr on train set: 11649\n",
    "# n_unqiue output for freq_sev on train set: 52516\n",
    "# n_unqiue output for cla_reg on train set: 14041\n",
    "# n_unqiue output for dlr on test set: 6773\n",
    "# n_unqiue output for freq_sev on test set: 23607\n",
    "# n_unqiue output for cla_reg on test set: 7633"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be12bf38",
   "metadata": {},
   "source": [
    "## check the size of each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for portion in [lr_out_train, lr_out_test]:\n",
    "    for pred in pred_col_names:\n",
    "        res.append(portion[f'bin_{pred}'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "res = pd.concat(res, axis=1)\n",
    "\n",
    "res = (\n",
    "    res\n",
    "    .set_axis(\n",
    "    # pd.MultiIndex.from_arrays([['train','train','train','test','test','test'], res.columns]), \n",
    "    pd.MultiIndex.from_arrays(\n",
    "        [['train']*len(pred_col_names) + ['test']*len(pred_col_names), res.columns]\n",
    "        ), \n",
    "    axis=1)\n",
    "    .rename_axis(['bin'], axis=0)\n",
    ")\n",
    "res\n",
    "\n",
    "sns.relplot(data=res.loc[:,'train'], kind='line').set(title='train set')\n",
    "sns.relplot(data=res.loc[:,'test'], kind='line').set(title='test set')\n",
    "\n",
    "# adj_bmi = 3:\n",
    "# dlr\n",
    "# 5556\n",
    "# 52366\n",
    "# 16742\n",
    "# 3304\n",
    "# 23566\n",
    "# 9094\n",
    "\n",
    "# for chosen model in report:\n",
    "# 21888\n",
    "# 52394\n",
    "# 38276\n",
    "# 11835\n",
    "# 23577\n",
    "# 19028\n",
    "\n",
    "# 11.9, 16.9\n",
    "# get enoguh bins such that prefer has >=8% (10)\n",
    "# get enoguh bins such that prefer has >=12%\n",
    "# perfer : (8,12)\n",
    "# standard: (60,75)\n",
    "# (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24aa4c",
   "metadata": {},
   "source": [
    "## check the records with lowest and highest predicted loss ratio by cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd60b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "# cols = ['substandard','risk_class', 'clean_record', 'bmi', chosen_pred_col_name]\n",
    "# cols = ['risk_class', 'clean_record', 'diff_low', 'diff_high', 'bmi_clip', 'bmi', chosen_pred_col_name]\n",
    "cols = ['clean_record', 'diff_low', 'diff_high', 'bmi_clip', 'bmi', chosen_pred_col_name]\n",
    "\n",
    "\n",
    "low_k = (\n",
    "    lr_out_test\n",
    "    .groupby(cohort_col)[cols]\n",
    "    .apply(lambda g: g.nsmallest(n=k, columns=chosen_pred_col_name, keep='first').reset_index(drop=True).rename_axis('top_record', axis=0))\n",
    ")\n",
    "\n",
    "high_k = lr_out_test.groupby(cohort_col)[cols].apply(lambda g: g.nlargest(n=k, columns=chosen_pred_col_name, keep='first').reset_index(drop=True).rename_axis('top_record', axis=0))\n",
    "\n",
    "# low_k.bmi.describe()\n",
    "# high_k.bmi.describe()\n",
    "\n",
    "top_records_full = pd.concat([low_k,high_k], keys=[f'low_{k}',f'high_{k}'], axis=1)\n",
    "\n",
    "# top_records_full\n",
    "top_records = top_records_full.loc[:, (slice(None), ['clean_record', 'bmi', chosen_pred_col_name])]\n",
    "\n",
    "\n",
    "top_records_full.to_excel(output_path / f\"top_records_full_{timestamp}.xlsx\")\n",
    "top_records.to_excel(output_path / f\"top_records_{timestamp}.xlsx\")\n",
    "\n",
    "\n",
    "top_records_full.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e5794",
   "metadata": {},
   "source": [
    "## check relation between bmi and bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmi_plot_cohort(test_only=True, bmi_offset=False):\n",
    "    portion_names = ['test'] if test_only else ['test','train']\n",
    "    portions = [lr_out_test] if test_only else [lr_out_test, lr_out_train]\n",
    "    # for portion_name, portion in zip(['test','train'], [lr_out_test, lr_out_train]):\n",
    "    for portion_name, portion in zip(portion_names, portions):\n",
    "        g = sns.relplot(data=portion, x='bmi', y=bin_chosen_pred_col_name, row='age_gp', col='sex_male', kind='scatter', style='clean_record', facet_kws={'sharex':False}, aspect=1.5)\n",
    "        \n",
    "        for ax in g.axes.flat:\n",
    "            _ = ax.set_xlabel('bmi')\n",
    "        suptitle = f'bmi vs bin by cohort for {chosen_pred_col_name} model on {portion_name} set (higher bin means higher risk)' \n",
    "        if bmi_offset: \n",
    "            suptitle += ' (with offset)'\n",
    "        g.figure.suptitle(suptitle, y=1.004, fontsize=15)\n",
    "        g.tight_layout()\n",
    "        \n",
    "        fig_name = \"bmi_vs_bin_cohort_offset\" if bmi_offset else \"bmi_vs_bin_cohort\"\n",
    "        savefig_plus(output_path/f\"{fig_name}_{portion_name}_{timestamp}.png\", dpi=150)\n",
    "\n",
    "bmi_plot_cohort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.relplot(data=lr_out_test, x='bmi', y=bin_chosen_pred_col_name, row='age_gp', col='sex_male', kind='scatter', style='clean_record', facet_kws={'sharex':False}, aspect=1.5)\n",
    "\n",
    "# # g = sns.relplot(data=lr_out_test, x='bmi', y=bin_chosen_pred_col_name, row='age_gp', col='sex_male', kind='scatter', facet_kws={'sharex':False}, aspect=1.5)\n",
    "# for ax in g.axes.flat:\n",
    "#     _ = ax.set_xlabel('bmi')\n",
    "# g.figure.suptitle(f'bmi vs bin by cohort for {chosen_pred_col_name} model (higher bin means higher risk)', y=1.004, fontsize=15)\n",
    "# g.tight_layout()\n",
    "\n",
    "# savefig_plus(output_path/f\"bmi_vs_bin_cohort_{timestamp}.png\", dpi=150)\n",
    "\n",
    "# # savefig_plus(output_path/f\"bmi_vs_bin_cohort_{timestamp}.pdf\")\n",
    "\n",
    "# # g = sns.relplot(data=lr_out_test, x='bmi', y=bin_chosen_pred_col_name, hue='age_gp', kind='scatter',facet_kws={'sharex':False}, aspect=2)\n",
    "# # savefig_plus(output_path/f\"bmi_vs_bin_overall_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c049589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_gp_interval_adult = [0,17,25,30,35,40,45,50,55,np.inf]\n",
    "def bmi_plot_child_adult(test_only=True, bmi_offset=False, invert_risk=False):\n",
    "    portion_names = ['test'] if test_only else ['test','train']\n",
    "    portions = [lr_out_test.copy()] if test_only else [lr_out_test.copy(), lr_out_train.copy()]\n",
    "    for portion_name, portion in zip(portion_names, portions):\n",
    "        age_gp_child = pd.cut(portion.app_age, list([0,5,10,17]), right=True, include_lowest=True)\n",
    "        age_gp_adult = pd.cut(portion.app_age, [18,25,30,35,40,45,50,55,np.inf], right=True, include_lowest=True)\n",
    "        fig, axes = plt.subplots(1,2,figsize=(20,9))\n",
    "        \n",
    "        if invert_risk: \n",
    "            portion[bin_chosen_pred_col_name] = 100 - portion[bin_chosen_pred_col_name]\n",
    "            suptitle = f\"bmi vs health score for {chosen_pred_col_name} model on {portion_name} set (higher health score means lower risk)\"\n",
    "        else:\n",
    "            suptitle = f\"bmi vs bin for {chosen_pred_col_name} model on {portion_name} set (higher bin means higher risk)\"\n",
    "            \n",
    "        ax = sns.scatterplot(data=portion.query(\"app_age<18\"), x='bmi', y=bin_chosen_pred_col_name, hue=age_gp_child, style='sex_male', ax=axes[0])\n",
    "        ax.set(title='app_age<18', \n",
    "               ylabel='health score (higher is lower risk)' if invert_risk else 'bin (higher is higher risk)',\n",
    "               )\n",
    "        # ax.legend(bbox_to_anchor =(1.3, 0.4))\n",
    "        \n",
    "        ax = (sns\n",
    "              .scatterplot(data=portion.query(\"app_age>=18\"), x='bmi', y=bin_chosen_pred_col_name, hue=age_gp_adult, style='sex_male', ax=axes[1])\n",
    "              .set(title='app_age>=18', \n",
    "                   ylabel='health score (higher is lower risk)' if invert_risk else 'bin (higher is higher risk)',\n",
    "                )\n",
    "        )\n",
    "        # suptitle = f\"bmi vs health score for original model on {portion_name} set\"\n",
    "        # suptitle = f\"bmi vs health score for updated model on {portion_name} set\"\n",
    "        # suptitle = f\"bmi vs bin for {chosen_pred_col_name} model on {portion_name} set (higher bin means higher risk)\"\n",
    "        # suptitle = f\"bmi vs health score for {chosen_pred_col_name} model on {portion_name} set (higher health score means lower risk)\"\n",
    "        \n",
    "        # if bmi_offset: \n",
    "        #     suptitle += ' (with offset)'\n",
    "        fig.suptitle(suptitle, y=0.95, fontsize=15)\n",
    "\n",
    "        # fig.tight_layout()\n",
    "        fig_name = \"bmi_vs_bin_by_app_age_offset\" if bmi_offset else \"bmi_vs_bin_by_app_age\"\n",
    "        savefig_plus(output_path/f\"{fig_name}_{portion_name}_{timestamp}.png\", dpi=150)\n",
    "    \n",
    "bmi_plot_child_adult()\n",
    "# for portion_name, portion in zip(['test','train'], [lr_out_test, lr_out_train]):\n",
    "#     age_gp_child = pd.cut(lr_out_test.app_age, list([0,5,10,17]), right=True, include_lowest=True)\n",
    "#     age_gp_adult = pd.cut(lr_out_test.app_age, [18,25,30,35,40,45,50,55,np.inf], right=True, include_lowest=True)\n",
    "#     fig, axes = plt.subplots(1,2,figsize=(20,9))\n",
    "#     g = sns.scatterplot(data=lr_out_test.query(\"app_age<18\"), x='bmi', y=bin_chosen_pred_col_name, hue=age_gp_child, style='sex_male', ax=axes[0]).set(title='app_age<18')\n",
    "#     g = sns.scatterplot(data=lr_out_test.query(\"app_age>=18\"), x='bmi', y=bin_chosen_pred_col_name, hue=age_gp_adult, style='sex_male', ax=axes[1]).set(title='app_age>=18')\n",
    "#     fig.suptitle(f\"bmi vs bin for {chosen_pred_col_name} model (higher bin means higher risk)\", y=0.95, fontsize=15)\n",
    "\n",
    "#     savefig_plus(output_path/f\"bmi_vs_bin_by_app_age_{timestamp}.png\", dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db88c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmi_plot_baby(test_only=True, bmi_offset=False):\n",
    "    portion_names = ['test'] if test_only else ['test','train']\n",
    "    portions = [lr_out_test] if test_only else [lr_out_test, lr_out_train]\n",
    "    for portion_name, portion in zip(portion_names, portions):\n",
    "        data = portion.query(\"app_age.between(0,7)\")\n",
    "        if not data.empty:\n",
    "            g = sns.relplot(data=data, x='bmi', y=bin_chosen_pred_col_name, hue='sex_male', col='app_age', col_wrap = 2, facet_kws={'sharex':False}, aspect=1.3, style='clean_record')\n",
    "            \n",
    "            suptitle = f'bmi vs bin of babies for {chosen_pred_col_name} model on {portion_name} set (higher bin means higher risk)'\n",
    "            if bmi_offset: \n",
    "                suptitle += ' (with offset)'\n",
    "            \n",
    "            g.figure.suptitle(suptitle, y=1.004, fontsize=15)\n",
    "            g.tight_layout()\n",
    "            \n",
    "            fig_name = \"bmi_vs_bin_babies_offset\" if bmi_offset else \"bmi_vs_bin_babies\"\n",
    "            savefig_plus(output_path/f\"{fig_name}_{portion_name}_{timestamp}.png\", dpi=150)\n",
    "\n",
    "bmi_plot_baby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_out_test.query(\"age_gp == @pd.Interval(10,15) and sex_male==0 and bmi>35\").sort_values('bin_dlr').sort_values('contract_no')[['contract_no','bin_dlr']] # similarly large bmi, but differing bins. This is due to occupational risk\n",
    "# .to_excel(\"strange_record.xlsx\") \n",
    "\n",
    "# lr_out_test.query(\"age_gp == @pd.Interval(15, 20) and sex_male==0 and bmi.between(48,53)\").sort_values(\"contract_no\")[['contract_no','bin_dlr']]  # both with high bmi and clean record, but given different bin. It seems that's because the one with lower bin is taller and heavier.\n",
    "\n",
    "\n",
    "# lr_out_test.query(\"age_gp == @pd.Interval(20, 25) and sex_male==1 and bmi.between(48,51)\") # two records with similarly high bmi, but one of them is clean record, and so one of them given low bin\n",
    "\n",
    "# lr_out_test.query(\"age_gp == @pd.Interval(25,30) and sex_male==1 and bmi.between(58,61)\") # high bmi, but due to clean record, still assigned low bin. Also, this person has very high weight. It seems the model thinks high weight is good.\n",
    "\n",
    "# lr_out_test.query(\"age_gp == @pd.Interval(30,35) and sex_male==1 and clean_record==0 and bmi.between(15,20)\").sort_values('bin_dlr') # very low bmi, no clean record, assigned a low bin \n",
    "\n",
    "\n",
    "# 83355824, 86861688\t\n",
    "# 80807254\n",
    "# 84405169\t\n",
    "# 85561023\t\n",
    "\n",
    "# lr_out_test.query(\"contract_no in ['85561023', '80807254','84405169']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19beb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check: how many unique bin edges \n",
    "# bins = np.quantile(lr_out_test[chosen_pred_col_name], q = np.arange(1/100, 1, 1/100))\n",
    "# bins\n",
    "# np.unique(bins).shape\n",
    "# lr_out_test[chosen_pred_col_name].value_counts(normalize=True)\n",
    "\n",
    "# pd.Series(np.digitize(lr_out_test[pred_col_name], bins=bins)).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d5f6c",
   "metadata": {},
   "source": [
    "# threshold tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55251dd",
   "metadata": {},
   "source": [
    "## helper functions for threshold tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stats(df, class_name, total_size, as_cohort=False, model_name=None, pref_bin=None, std_bin=None, margin_bin=None):\n",
    "    d = {}\n",
    "    \n",
    "    if as_cohort:\n",
    "        d['class'] = class_name\n",
    "        d['model_name'] = model_name\n",
    "        d['pref_bin'] = pref_bin\n",
    "        d['std_bin'] = std_bin\n",
    "        d['margin_bin'] = margin_bin\n",
    "        \n",
    "    d['prop'] = len(df)/total_size\n",
    "    d['n'] = len(df)\n",
    "    \n",
    "    d.update(\n",
    "        df\n",
    "        .risk_class\n",
    "        .value_counts(normalize=False)\n",
    "        .rename({\n",
    "            'standard': 'std_n',\n",
    "            'substandard': 'substd_n',\n",
    "            'decline': 'decline_n'\n",
    "            })\n",
    "        # .sort_index()\n",
    "        .to_dict()\n",
    "    )\n",
    "    # print(d)\n",
    "    \n",
    "    for cls in['std','substd','decline']:\n",
    "        if f\"{cls}_n\" not in d:\n",
    "            d[f\"{cls}_n\"] = 0\n",
    "        d[f\"{cls}_prop\"] = d[f\"{cls}_n\"]/d['n']\n",
    "    \n",
    "    # print(d['decline_n'])\n",
    "    \n",
    "    d['nonstd_prop'] = (d['substd_n'] + d['decline_n'])/d['n']\n",
    "    \n",
    "    d['lr'] = df.tot_pay_amt.sum()/df.eff_annual_prem.sum() if len(df) > 0 and df.eff_annual_prem.sum() != 0 else 0\n",
    "    \n",
    "    d['tot_pay_amt'] = df.tot_pay_amt.sum()\n",
    "    d['eff_annual_prem'] = df.eff_annual_prem.sum()\n",
    "    \n",
    "    # d['lr'] = df.tot_pay_amt.sum()/df.eff_annual_prem.sum()\n",
    "    \n",
    "    # for these two classes, also calculate their precision (i.e., agreement rate)\n",
    "    if class_name == 'P_S':\n",
    "        d['precision'] = df.risk_class.eq('standard').mean()\n",
    "    elif class_name == 'M_N':\n",
    "        # d['precision'] = df.risk_class.ne('standard').mean()\n",
    "        d['precision'] = df.risk_class.isin(['substandard','decline']).mean()\n",
    "    else:\n",
    "        d['precision'] = np.nan\n",
    "    \n",
    "    return d if as_cohort else pd.Series(d, name=class_name)\n",
    "    # return pd.Series(d) if as_cohort else pd.Series(d, name=class_name)\n",
    "    \n",
    "def find_stats_cohort(df, class_name, total_size, cohort_col, model_name=None, pref_bin=None, std_bin=None, margin_bin=None):\n",
    "    # df contains records in a particular class\n",
    "    # print(df)\n",
    "    \n",
    "    # each g is a cohort in a particular class (pref, std, M_N)\n",
    "    return df.groupby(cohort_col).apply(lambda g: find_stats(g, class_name, total_size, as_cohort=True, model_name=model_name, pref_bin=pref_bin, std_bin=std_bin, margin_bin=margin_bin)).apply(pd.Series).reset_index()\n",
    "    # return df.groupby(cohort_col).apply(lambda df: find_stats(df, class_name, total_size, as_cohort=True, model_name=model_name, pref_bin=pref_bin, std_bin=std_bin, margin_bin=margin_bin)).apply(pd.Series).reset_index()\n",
    "\n",
    "def find_pct_diff_lr(s1:pd.Series, s2:pd.Series, index_name='lr'):\n",
    "    # return (s1[index_name]-s2[index_name])/(s2[index_name])*100\n",
    "    return (s1[index_name]-s2[index_name])/(s2[index_name])\n",
    "\n",
    "def find_pct_diff_lr_plus(s1:pd.Series, s2:pd.Series):\n",
    "    s1_trim = s1[s1.index.str.startswith('lr')]\n",
    "    s2_trim = s2[s2.index.str.startswith('lr')]\n",
    "    return ((s1_trim-s2_trim)/s2_trim).add_prefix(f\"prop_diff_{s1_trim.name}_{s2_trim.name}_\")\n",
    "\n",
    "# find_stats_cohort(lr_out_test, \"M_N\", len(lr_out_test))\n",
    "find_stats_cohort(lr_out_test, \"pref\", len(lr_out_test), cohort_col=cohort_col)\n",
    "\n",
    "# find_stats(lr_out_test, \"prefer\", len(lr_out_test))\n",
    "find_stats(lr_out_test, \"M_N\", len(lr_out_test))\n",
    "\n",
    "# prop                1.00000\n",
    "# n               26711.00000\n",
    "# std_n           24008.00000\n",
    "# substd_n         2073.00000\n",
    "# decline_n         630.00000\n",
    "# std_prop            0.89881\n",
    "# substd_prop         0.07761\n",
    "# decline_prop        0.02359\n",
    "# nonstd_prop         0.10119\n",
    "# lr                  0.59039\n",
    "# precision           0.10119\n",
    "# Name: M_N, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32690822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_bin(lr_out_test=None, bin_to_prop=None, bin_col_name=None, sizes=None, prev_bin=None, ):\n",
    "def find_bin(s=None, sizes=None, prev_bin=None):\n",
    "    # prev_bin: the ending bin of the previous risk_class.\n",
    "    # if given, then find the bin number `res` (start counting from from prev_bin +1) such that the proportion of data from {prev_bin+1, prev_bin+2,..., res} = size\n",
    "    # print(bin_to_prop)\n",
    "    \n",
    "    # ---------------------- directly operate on Series ---------------------- #\n",
    "    # treat `index` as bin number\n",
    "    bin_to_prop = s.value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    # print(bin_to_prop)\n",
    "    \n",
    "    if prev_bin:\n",
    "        # bin_to_prop = bin_to_prop.loc[prev_bin+1:]\n",
    "        bin_to_prop = bin_to_prop[bin_to_prop.index>prev_bin]\n",
    "    \n",
    "    return [\n",
    "        bin_to_prop\n",
    "        # .index[bin_to_prop.cumsum().ge(size).argmax()] \n",
    "        .index[\n",
    "            # find the first bin with cumulative proportion larger than size\n",
    "            res[0] if (res:=np.where(bin_to_prop.cumsum().gt(size))[0]).size>0 \n",
    "            # if such bin doesn't exist, then return the last bin\n",
    "            else len(bin_to_prop)-1 # return the last element\n",
    "            ]\n",
    "        for size in sizes\n",
    "    ]    \n",
    "\n",
    "\n",
    "# ------------------------------- testing code ------------------------------- #\n",
    "s = lr_out_test[bin_chosen_pred_col_name]\n",
    "bin_to_prop = s.value_counts(normalize=True).sort_index()\n",
    "# find_bin(bin_to_prop, sizes=[0.1, 0.12], prev_bin=None)\n",
    "# find_bin(s, sizes=[0.81], prev_bin=1)\n",
    "# find_bin(s, sizes=[0.2,0.5], prev_bin=1)\n",
    "find_bin(s, sizes=[0.2,0.5])\n",
    "# find_bin(s, sizes=[0.75], prev_bin=1)\n",
    "# find_bin(bin_to_prop, sizes=[0.75], prev_bin=1)\n",
    "# find_bin(lr_out_test, bin_chosen_pred_col_name, sizes=[0.1, 0.12], prev_bin=None)\n",
    "\n",
    "# res = bin_to_prop.iloc[bin_to_prop.prop.cumsum().ge(size).argmax(), 0]\n",
    "# print(res)\n",
    "# return res\n",
    "\n",
    "# bin_to_prop = bin_to_prop.reset_index().set_axis(['bin','prop'], axis=1)\n",
    "# print(bin_to_prop.cumsum().gt(0.09).argmax())\n",
    "# print(bin_prefer)\n",
    "# temp = bin_to_prop.query(\"bin>@bin_prefer\")\n",
    "# bin_std = temp.iloc[temp.prop.cumsum().ge(size_dict['std']).argmax(), 0]\n",
    "# print(bin_std)\n",
    "\n",
    "# temp = bin_to_prop.query(\"bin>@bin_std\")\n",
    "# bin_margin = temp.iloc[temp.prop.cumsum().ge(size_dict['margin']).argmax(), 0]\n",
    "# print(bin_margin)\n",
    "\n",
    "# size_dict = {'prefer':0.1, 'std':0.8, 'margin':0.02}\n",
    "# find_bin(lr_out_test, 'bin_dlr', size=0.8, prev_bin=18)\n",
    "# find_bin(lr_out_test, 'bin_dlr', sizes=[0.1, 0.11], prev_bin=None)\n",
    "\n",
    "bin_to_prop.cumsum().loc[51]\n",
    "# len(s[s<=18])/len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4665440b",
   "metadata": {},
   "source": [
    "## function to do threshold tuning\n",
    "- index i, j, k:\n",
    "    - i: the ending bin of prefer class (inclusive)\n",
    "        - prefer class has bins between 1 and i\n",
    "    - j: the ending bin of std class (inclusive)\n",
    "        - std class has bins between i+1 and j\n",
    "    - k: the ending bin of margin class (inclusive)\n",
    "        - margin class has bins between j+1 and k\n",
    "    - k+1: the starting bin of nonstd class (inclusive)\n",
    "        - nonstd class has bins between k+1 and 100\n",
    "\n",
    "- usual range of size for each risk class\n",
    "    - prefer: 8-12\n",
    "    - standard: 73-82\n",
    "    - margin: 1-4\n",
    "    - nonstd: 7-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac38a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lr_threshold(lr_out_test, n_bins, bin_col_name, model_name, cohort_col):\n",
    "    total_size = len(lr_out_test)\n",
    "    lr_out_test = lr_out_test.sort_values(bin_col_name) # sort according to the given model prediction\n",
    "    \n",
    "    # find the starting index of each bin. Note: the bins have already been sorted in ascending order\n",
    "    bin_start = pd.Series(\n",
    "        lr_out_test[bin_col_name]\n",
    "        .searchsorted(range(1,n_bins+1)), index=range(1,n_bins+1)\n",
    "        )\n",
    "    \n",
    "    # print(bin_start)\n",
    "    \n",
    "    # this will store the results of all bin combinations\n",
    "    res = []\n",
    "    \n",
    "    res_cohort = []\n",
    "\n",
    "    # find the starting bin and ending bin for prefer class\n",
    "    range_start, range_end = find_bin(\n",
    "        s=lr_out_test[bin_col_name], \n",
    "        sizes=[0.07, 0.13]\n",
    "        # sizes=[0.08, 0.12]\n",
    "    )\n",
    "    # print('i')\n",
    "    # print(range_start, range_end+1)\n",
    "    \n",
    "    # for i in range(range_start, range_end+1): \n",
    "    for i in range(range_start, range_end): \n",
    "        data_pref = lr_out_test[:bin_start[i+1]]\n",
    "        stats_pref = find_stats(df=data_pref, class_name='pref', total_size=total_size)\n",
    "        \n",
    "        # find the starting bin and ending bin for std class\n",
    "        range_start, range_end = find_bin(\n",
    "            s=lr_out_test[bin_col_name], \n",
    "            sizes=[0.73, 0.83], \n",
    "            # sizes=[0.82, 0.83],  # for testing only\n",
    "            prev_bin=i\n",
    "            )\n",
    "        # print('j')\n",
    "        # print(range_start, range_end+1)\n",
    "        \n",
    "        # for j in range(range_start, range_end+1):\n",
    "        for j in range(range_start, range_end):\n",
    "            # print(bin_start[i+1], bin_start[j+1])\n",
    "            data_std = lr_out_test[bin_start[i+1]: bin_start[j+1]]\n",
    "            \n",
    "            stats_std = find_stats(df=data_std, class_name='std', total_size=total_size)\n",
    "            stats_P_S = find_stats(\n",
    "                df=pd.concat([data_pref, data_std], axis=0), \n",
    "                class_name='P_S', \n",
    "                total_size=total_size\n",
    "                )\n",
    "            \n",
    "            # find the starting bin and ending bin for margin class\n",
    "            range_start, range_end = find_bin(\n",
    "                s=lr_out_test[bin_col_name], \n",
    "                sizes=[0.01, 0.03], \n",
    "                prev_bin=j\n",
    "                )\n",
    "            # for k in range(j+1, n_bins):\n",
    "            # print('k')\n",
    "            # print(range_start, range_end+1)\n",
    "            \n",
    "            # for k in range(range_start, range_end+1):\n",
    "            for k in range(range_start, range_end):\n",
    "                # if k is already the last bin, then doing `bin_start[k+1]` will result in error...\n",
    "                data_margin = lr_out_test[bin_start[j+1]: bin_start[k+1]]\n",
    "                data_nonstd = lr_out_test[bin_start[k+1]:]\n",
    "                \n",
    "                stats_margin = find_stats(df=data_margin, class_name='margin', total_size=total_size)\n",
    "                \n",
    "                stats_nonstd = find_stats(df=data_nonstd, class_name='nonstd', total_size=total_size)\n",
    "                \n",
    "                \n",
    "                data_M_N = pd.concat([data_margin, data_nonstd], axis=0)\n",
    "                stats_M_N = find_stats(\n",
    "                    df=data_M_N, \n",
    "                    class_name='M_N', \n",
    "                    total_size=total_size\n",
    "                    )\n",
    "                \n",
    "                for df, class_name in zip([data_pref, data_std, data_M_N], ['pref', 'std', 'M_N']):\n",
    "                    res_cohort.append(find_stats_cohort(df=df, class_name=class_name, total_size=len(df), cohort_col=cohort_col, model_name=model_name, pref_bin=i, std_bin=j, margin_bin=k))\n",
    "                # res_cohort.append(find_stats_cohort(df=data_std, class_name='std', total_size=total_size, model_name=model_name, pref_bin=i, std_bin=j, margin_bin=k))\n",
    "                # res_cohort.append(find_stats_cohort(df=data_M_N, class_name='M_N', total_size=total_size, model_name=model_name, pref_bin=i, std_bin=j, margin_bin=k))\n",
    "                \n",
    "                # print(i,j,k)\n",
    "                misc_info = pd.Series({\n",
    "                    'model_name': model_name,\n",
    "                    'pref_bin': i,\n",
    "                    'std_bin': j,\n",
    "                    'margin_bin': k,\n",
    "                    # 'prop_diff_pref_std_lr': find_pct_diff_lr(stats_pref, stats_std),\n",
    "                    # 'prop_diff_std_M_N_lr': find_pct_diff_lr(stats_std, stats_M_N),\n",
    "                    # 'prop_diff_std_margin': find_pct_diff_lr(stats_std, stats_margin),\n",
    "                    # 'prop_diff_margin_nonstd': find_pct_diff_lr(stats_margin, stats_nonstd),\n",
    "                })\n",
    "                \n",
    "                misc_info = pd.concat([\n",
    "                    misc_info, \n",
    "                    find_pct_diff_lr_plus(stats_pref, stats_std),\n",
    "                    find_pct_diff_lr_plus(stats_std, stats_M_N),\n",
    "                    ], axis=0)\n",
    "                \n",
    "                # print(misc_info)\n",
    "                \n",
    "                # each appended dataframe has one row only\n",
    "                res.append(pd.concat({\n",
    "                    '': misc_info, \n",
    "                    'pref': stats_pref, \n",
    "                    'std': stats_std, \n",
    "                    'M_N': stats_M_N, \n",
    "                    'margin': stats_margin, \n",
    "                    'nonstd': stats_nonstd, \n",
    "                    'P_S': stats_P_S,\n",
    "                    },\n",
    "                    axis=0\n",
    "                ).to_frame().T\n",
    "                )\n",
    "                \n",
    "    # print(len(res))\n",
    "    return pd.concat(res, axis=0, ignore_index=True), pd.concat(res_cohort, axis=0, ignore_index=True)\n",
    "\n",
    "# a, b = evaluate_lr_threshold(\n",
    "#         lr_out_test, n_bins=n_bins, bin_col_name=f\"bin_dlr\", model_name=pred_col_name\n",
    "#     )\n",
    "# a\n",
    "# b[:24*3+1]\n",
    "\n",
    "res_indiv, res_cohort = [], []\n",
    "for pred_col_name in pred_col_names:\n",
    "# for pred_col_name in pred_col_names[:1]:\n",
    "    df_indiv, df_cohort = evaluate_lr_threshold(\n",
    "        lr_out_test, n_bins=n_bins, bin_col_name=f\"bin_{pred_col_name}\", model_name=pred_col_name, cohort_col=cohort_col\n",
    "    )\n",
    "    res_indiv.append(df_indiv)\n",
    "    res_cohort.append(df_cohort)\n",
    "df_res = pd.concat(res_indiv, axis=0)\n",
    "df_res\n",
    "\n",
    "df_res_cohort = pd.concat(res_cohort, axis=0)\n",
    "df_res_cohort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2112d8b",
   "metadata": {},
   "source": [
    "## create new df to put important columns to front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5575358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_columns(df_res):\n",
    "    # ------------------------- flatten the column index ------------------------- #\n",
    "    df_res_flat = (\n",
    "        df_res\n",
    "        .set_axis(['_'.join(s for s in col if s).strip() for col in df_res.columns.values], axis=1)\n",
    "        # .sort_index(axis=1)\n",
    "        # .sort_index(axis=1, key=lambda s: s.str.extract(r'_([^_]*)$')) # sort by the last suffix \n",
    "        # .sort_index(axis=1, key=lambda s: res if (res:= s.str.extract(r'_([^_]*)$')) is not None else 'a') # sort by the last suffix \n",
    "    )\n",
    "\n",
    "    # --------------- convert columns of int type back to int type --------------- #\n",
    "    # [col for col in df_res_flat.columns if re.search(r'_n$|_bin$', col)]\n",
    "    cols_int = df_res_flat.columns[df_res_flat.columns.str.contains(pat=r'_n$|_bin$')] # those with suffix `_n` or `_bin`\n",
    "    df_res_flat[cols_int] = df_res_flat[cols_int].astype(int)\n",
    "\n",
    "    # ------------- put these columns to the front for easy reference ------------- #\n",
    "    cols_to_front = [\n",
    "        'model_name',\n",
    "        'pref_bin',\n",
    "        'std_bin',\n",
    "        'margin_bin',\n",
    "        'pref_prop',\n",
    "        'std_prop',\n",
    "        'margin_prop',\n",
    "        'M_N_prop',\n",
    "        'prop_diff_pref_std_lr',\n",
    "        'prop_diff_std_M_N_lr',\n",
    "        'pref_decline_prop',\n",
    "        'std_decline_prop',\n",
    "        'M_N_decline_prop',\n",
    "        # 'pref_substd_prop',\n",
    "        # 'std_substd_prop',\n",
    "        # 'M_N_substd_prop',\n",
    "        'P_S_precision',\n",
    "        'M_N_precision',\n",
    "        # 'nonstd_prop',\n",
    "    ]\n",
    "\n",
    "    # df_res_flat = df_res_flat[cols_to_front + [ col for col in df_res_flat.columns if col not in cols_to_front ]]\n",
    "    # return df_res_flat\n",
    "    return df_res_flat[cols_to_front + [ col for col in df_res_flat.columns if col not in cols_to_front ]]\n",
    "\n",
    "df_res_flat = reorder_columns(df_res)\n",
    "df_res_flat.head(2)\n",
    "# list(df_res_flat.columns)\n",
    "# df_res_flat.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a5b17b",
   "metadata": {},
   "source": [
    "## create new df for documenting on sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84632358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_excel(df_res_flat, schema, table):\n",
    "    cols_excel = [\n",
    "        'model_name',\n",
    "        'pref_bin',\n",
    "        'std_bin',\n",
    "        'margin_bin',\n",
    "        \n",
    "        'P_S_lr',\n",
    "        'prop_diff_P_S_HS', # placeholder\n",
    "        'P_S_prop',\n",
    "        'P_S_precision',\n",
    "        \n",
    "        'M_N_lr',\n",
    "        'prop_diff_M_N_HS', # placeholder\n",
    "        'M_N_prop',\n",
    "        'M_N_precision',\n",
    "        \n",
    "        'prop_diff_pref_std_lr',\n",
    "        'prop_diff_std_M_N_lr',\n",
    "        \n",
    "        'pref_lr',\n",
    "        'std_lr',\n",
    "        'margin_lr',\n",
    "        'nonstd_lr',\n",
    "        \n",
    "        'prop_diff_pref_HS', # placeholder\n",
    "        'prop_diff_std_HS', # placeholder\n",
    "        'prop_diff_margin_HS', # placeholder\n",
    "        'prop_diff_nonstd_HS', # placeholder\n",
    "\n",
    "        'pref_prop',\n",
    "        'std_prop',\n",
    "        'margin_prop',\n",
    "        'nonstd_prop',\n",
    "        \n",
    "        'pref_decline_prop',\n",
    "        'std_decline_prop',\n",
    "        'M_N_decline_prop',\n",
    "        \n",
    "        # 'pref_substd_prop',\n",
    "        # 'std_substd_prop',\n",
    "        # 'M_N_substd_prop',\n",
    "        \n",
    "        # 'pref_decline_prop',\n",
    "        # 'std_decline_prop',\n",
    "        # 'M_N_decline_prop',\n",
    "        \n",
    "        'pref_nonstd_prop',\n",
    "        'std_nonstd_prop',\n",
    "        'M_N_nonstd_prop',\n",
    "        \n",
    "        'table',\n",
    "        'combo',\n",
    "        'sql',\n",
    "    ]\n",
    "\n",
    "    # schema, table = tables['res_out']\n",
    "    df_res_excel = (\n",
    "        df_res_flat\n",
    "        .assign(\n",
    "            prop_diff_P_S_HS = 0,\n",
    "            prop_diff_M_N_HS = 0,\n",
    "            prop_diff_pref_HS = 0,\n",
    "            prop_diff_std_HS = 0,\n",
    "            prop_diff_margin_HS = 0,\n",
    "            prop_diff_nonstd_HS = 0,\n",
    "            table=f\"{schema}.{table}\",\n",
    "            combo='',\n",
    "            sql = df_res_flat.apply(\n",
    "                lambda row: f\"SELECT * FROM {schema}.{table} WHERE pref_bin = {row.pref_bin} AND std_bin = {row.std_bin} AND margin_bin = {row.margin_bin} AND model_name = '{row.model_name}'\", axis=1\n",
    "                )\n",
    "        )\n",
    "        [cols_excel]\n",
    "    )\n",
    "    return df_res_excel \n",
    "\n",
    "df_res_excel = pd.concat([\n",
    "    make_df_excel(df_res_flat, schema=tables['res_out'][0], table=tables['res_out'][1]), \n",
    "    df_res_flat.filter(regex=r'prop_diff_pref_std_lr_|prop_diff_std_M_N_lr_', axis=1).sort_index(axis=1)\n",
    "    ], axis=1)\n",
    "\n",
    "df_res_excel.head(2)\n",
    "\n",
    "# df_res_excel = pd.concat([\n",
    "#     df_res_excel, df_res_flat.filter(regex=r'prop_diff_pref_std_lr_|prop_diff_std_M_N_lr_', axis=1).sort_index(axis=1)\n",
    "#     ], axis=1)\n",
    "# # df_res_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342009b6",
   "metadata": {},
   "source": [
    "# export data to db and local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33542f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(df_res_flat, df_res_excel, df_res_cohort, schema, table):\n",
    "    # schema, table = tables['res_out']\n",
    "    # _, table_no_ts = tables['res_out_no_ts']\n",
    "    # print(table)\n",
    "\n",
    "    # table = '_'.join([table, timestamp])\n",
    "\n",
    "    print(f\"{schema = }\")\n",
    "    print(f\"{table = }\")\n",
    "    print(f\"original df output name: df_res_flat_{table}.csv\")\n",
    "    print(f\"excel format name: df_res_excel_{table}.xlsx\")\n",
    "    print(f\"table name in db: {table}\")\n",
    "    print(f\"table name by cohort in db: {'_'.join([table,'cohort'])}\")\n",
    "\n",
    "    # ------------------------------ output results ------------------------------ #\n",
    "    df_res_flat.to_excel(output_path/f\"df_res_flat_{table}.xlsx\")\n",
    "    df_res_excel.to_excel(output_path/f\"df_res_excel_{table}.xlsx\")\n",
    "    export_to_db(df_res_flat, schema=schema, table=table, if_exists='replace')\n",
    "    export_to_db(df_res_cohort.astype({'age_gp':'str'}), schema=schema, table='_'.join([table,\"cohort\"]), if_exists='replace')\n",
    "    # export_to_db(df_res_flat, schema=schema, table=table_no_ts, if_exists='replace')\n",
    "    # export_to_db(df_res_cohort.astype({'age_gp':'str'}), schema=schema, table='_'.join([table_no_ts,\"cohort\"]), if_exists='replace')\n",
    "\n",
    "    # df_res_excel.to_csv(output_path/'_'.join([tables['lr_out'][1], timestamp, \"df_res_excel.csv\"]))\n",
    "    # tables\n",
    "    \n",
    "export_results(df_res_flat, df_res_excel, df_res_cohort, schema=tables['res_out'][0], table=tables['res_out'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf3341",
   "metadata": {},
   "source": [
    "# bmi offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3ac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bmi_offset:\n",
    "    lr_out_test_offset = lr_out_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust bmi by cohort\n",
    "# global_record_count = 0\n",
    "# def add_offset_bmi(g):\n",
    "#     global global_record_count\n",
    "#     low_limit = 0.003\n",
    "#     high_limit = 0.997\n",
    "#     base = 40\n",
    "#     bmi_low, bmi_high = g.bmi.quantile(low_limit), g.bmi.quantile(high_limit)\n",
    "#     print(f\"for cohort {g.name}: \")\n",
    "#     print(bmi_low, bmi_high)\n",
    "#     print(\"number of affected records: \")\n",
    "#     global_record_count += g.query(f\"~bmi.between({bmi_low}, {bmi_high})\").shape[0]\n",
    "#     print(g.query(f\"~bmi.between({bmi_low}, {bmi_high})\").shape[0])\n",
    "    \n",
    "#     for pred_col_name in pred_col_names:\n",
    "#         g[pred_col_name] = np.where(\n",
    "#             g.bmi.between(bmi_low, bmi_high),\n",
    "#             g[pred_col_name],\n",
    "#             np.clip(g[pred_col_name] + base, a_min=1, a_max=100)\n",
    "#             # np.clip(g.bin_dlr + base + , a_min=0, a_max=100)\n",
    "#         )\n",
    "#     return g\n",
    "\n",
    "# # lr_out_test = lr_out_test.groupby(cohort_col).apply(add_offset_bmi)\n",
    "# lr_out_test.groupby(cohort_col).apply(add_offset_bmi)\n",
    "# global_record_count\n",
    "\n",
    "# # lr_out_test.groupby(cohort_col).apply(play)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c110b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_limit = 0.002\n",
    "# high_limit = 0.998\n",
    "# bmi_low, bmi_high = lr_out_test_offset.bmi.quantile(low_limit), lr_out_test_offset.bmi.quantile(high_limit)\n",
    "# (lr_out_test_offset.bmi.between(bmi_low, bmi_high)) | (lr_out_test_offset[f\"bin_{pred_col_name}\"] > 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9702b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1: add a constant to all record with extreme bmi\n",
    "if bmi_offset:\n",
    "    low_limit = 0.002\n",
    "    high_limit = 0.998\n",
    "    base = 50\n",
    "    bmi_low, bmi_high = lr_out_test_offset.bmi.quantile(low_limit), lr_out_test_offset.bmi.quantile(high_limit)\n",
    "    bmi_low, bmi_high\n",
    "    for pred_col_name in pred_col_names:\n",
    "        # print(pred_col_name)\n",
    "        lr_out_test[f\"bin_{pred_col_name}\"] = np.where(\n",
    "            lr_out_test_offset.bmi.between(bmi_low, bmi_high),\n",
    "            # (lr_out_test_offset.bmi.between(bmi_low, bmi_high)) | (lr_out_test_offset[f\"bin_{pred_col_name}\"] > 50),\n",
    "            lr_out_test_offset[f\"bin_{pred_col_name}\"],\n",
    "            np.clip(lr_out_test_offset[f\"bin_{pred_col_name}\"] + base, a_min=1, a_max=100)\n",
    "            # np.clip(lr_out_test_offset.bin_dlr + base + , a_min=0, a_max=100)\n",
    "            )\n",
    "\n",
    "    # show the records that have received offset\n",
    "    lr_out_test.query(f\"~bmi.between({bmi_low}, {bmi_high})\")\n",
    "    lr_out_test.query(f\"~bmi.between({bmi_low}, {bmi_high})\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M2: add a constant and a linear penalty to records with extreme bmi\n",
    "# if bmi_offset:\n",
    "#     base = 20\n",
    "#     multiplier = 3\n",
    "#     bmi_low, bmi_high = lr_out_test_offset.bmi.quantile(low_limit), lr_out_test_offset.bmi.quantile(high_limit)\n",
    "\n",
    "#     lr_out_test['bin_dlr'] = (\n",
    "#         lr_out_test_offset.bin_dlr + \n",
    "#         lr_out_test_offset.bmi.apply(\n",
    "#             lambda v: base + ceil(v-bmi_high)*multiplier if v>=bmi_high\n",
    "#             else 0 if bmi_low< v< bmi_high\n",
    "#             else base + ceil(bmi_low - v)*multiplier \n",
    "#             )\n",
    "#     ).clip(upper=100)\n",
    "\n",
    "#     # lr_out_test_offset.query(f\"~bmi.between({bmi_low}, {bmi_high})\")\n",
    "#     lr_out_test.query(f\"~bmi.between({bmi_low}, {bmi_high})\")\n",
    "#     # # lr_out_test.query(f\"~bmi.between({bmi_low}, {bmi_high})\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed04db3",
   "metadata": {},
   "source": [
    "## check relation between bmi and bin after bmi offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fa757",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bmi_offset:\n",
    "    bmi_plot_cohort(bmi_offset=True)\n",
    "    bmi_plot_child_adult(bmi_offset=True)\n",
    "    bmi_plot_baby(bmi_offset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e156d6",
   "metadata": {},
   "source": [
    "# tuning after bmi offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ef9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bmi_offset:\n",
    "    # ---------------------------- get tunning results --------------------------- #\n",
    "    res_indiv, res_cohort = [], []\n",
    "    for pred_col_name in pred_col_names:\n",
    "    # for pred_col_name in pred_col_names[:1]:\n",
    "        df_indiv, df_cohort = evaluate_lr_threshold(\n",
    "            lr_out_test, n_bins=n_bins, bin_col_name=f\"bin_{pred_col_name}\", model_name=pred_col_name, cohort_col=cohort_col\n",
    "        )\n",
    "        res_indiv.append(df_indiv)\n",
    "        res_cohort.append(df_cohort)\n",
    "    df_res = pd.concat(res_indiv, axis=0)\n",
    "    df_res\n",
    "\n",
    "    df_res_cohort = pd.concat(res_cohort, axis=0)\n",
    "    df_res_cohort\n",
    "    \n",
    "    # ------------------------------ reorder columns ----------------------------- #\n",
    "    df_res_flat = reorder_columns(df_res)\n",
    "    df_res_flat.head(2)\n",
    "    \n",
    "    df_res_excel = pd.concat([\n",
    "        make_df_excel(df_res_flat, schema=tables['res_out_offset'][0], table=tables['res_out_offset'][1]), \n",
    "        df_res_flat.filter(regex=r'prop_diff_pref_std_lr_|prop_diff_std_M_N_lr_', axis=1).sort_index(axis=1)\n",
    "        ], axis=1)\n",
    "\n",
    "    df_res_excel.head(2)\n",
    "    \n",
    "    # ------------------------------ export results ------------------------------ #\n",
    "    export_results(df_res_flat, df_res_excel, df_res_cohort, schema=tables['res_out_offset'][0], table=tables['res_out_offset'][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863aafd",
   "metadata": {},
   "source": [
    "# adhoc code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb4910",
   "metadata": {},
   "source": [
    "## digression: experiment to illustrate data with duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.quantile([1,2], q=np.arange(1/100, 1, 1/100))\n",
    "\n",
    "# data = [1, 1.0001, 1.9, 2]\n",
    "# data = [1, 1.01, 1.01, 20, 30,  99.99, 99.9999, 100]\n",
    "# data = [1, 1.01, 1.001, 20, 30,31,99,12, 100]\n",
    "# data = [1,1,1,1,1,1.01, 1.02, 2,3,4]\n",
    "\n",
    "\n",
    "# Q: why the bin edges aren't unique when we have duplicate values? Eg., why we have some bin edges being the same when we have many values of `1`?\n",
    "# A: because about 10% of the data is 1, and so `1` will occupies 10 bins, because each bin should contain about 1% of the data\n",
    "# data = [1]*10 + list(range(1,101,1))\n",
    "# print(\"data: \")\n",
    "# print(data)\n",
    "\n",
    "# # data_unique = pd.Series(data).drop_duplicates()\n",
    "# # bins = np.quantile(data_unique, q=np.arange(1/100, 1, 1/100))\n",
    "# bins = np.quantile(data, q=np.arange(1/100, 1, 1/100))\n",
    "\n",
    "# print(\"bin edges:\")\n",
    "# bins\n",
    "\n",
    "# print(\"\")\n",
    "# np.digitize(data, bins=bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.catplot(data=df_prop_diff_cohort.query(f\"pref_bin=={pref_bin} and std_bin=={std_bin} and margin_bin=={margin_bin}\"), x='prop_diff', y='age_gp', ci=None, row='sex_male', col='comb', kind='bar', sharex=False).set(xlabel='proportion difference')\n",
    "# g.refline(x=0, color='r', lw=3, label='diff = 0')\n",
    "# g.figure.suptitle('proportion difference between predicted risk classes', fontsize=15, y=1.01)\n",
    "# g.tight_layout()\n",
    "# g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4e73b",
   "metadata": {},
   "source": [
    "## use pointsize to distinguish record count size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71323f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df_res_cohort.query(\"pref_bin==12 and std_bin==91 and margin_bin==93\").astype({'age_gp':'str'})\n",
    "# g = sns.relplot(data=data, y='lr', x=data['age_gp'].astype('str'), kind='line',  hue='class', col='sex_male', style='class', ci=None, aspect=1.3, markers=True, markersize=7, lw=2).set(ylabel='loss ratio')\n",
    "# g.figure.suptitle('loss ratio of each predicted risk class', fontsize=15)\n",
    "# g.tight_layout()\n",
    "# g.set_xticklabels(rotation=30, ha=\"right\")\n",
    "\n",
    "\n",
    "# for col, ax in g.axes_dict.items():\n",
    "#     ax2 = ax.twinx()\n",
    "#     ax2.tick_params(axis='y', colors='b') \n",
    "#     ax2.grid(visible=False)\n",
    "#     # ax2.set_ylim(0,100)\n",
    "#     # print(data.query(\"sex_male == @col\"))\n",
    "#     # sns.lineplot(data=data.query(\"sex_male == @col\"), x='age_gp', y='n', ax=ax2, ci=None, marker=True, markers='*', markersize=30, linestyle='--', color='b')\n",
    "#     sns.pointplot(data=data.query(\"sex_male == @col\"), x='age_gp', y='n', hue='class', ax=ax2, ci=None, markers='o', linestyles='', scale=0.8)\n",
    "#     ax2.set_ylabel('record count')\n",
    "# g.tight_layout()\n",
    "\n",
    "\n",
    "# g = sns.relplot(data=data, y='lr', x=data['age_gp'].astype('str'), kind='scatter',  hue='class', col='sex_male', aspect=1.3, size='n', sizes=(10,100)).set(ylabel='loss ratio', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e25b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_stats(df, class_name, total_size):\n",
    "#     d = {}\n",
    "#     d['prop'] = len(df)/total_size\n",
    "#     d['n'] = len(df)\n",
    "#     d.update(\n",
    "#         df\n",
    "#         .risk_class\n",
    "#         .value_counts(normalize=False)\n",
    "#         .rename({\n",
    "#             'standard': 'std_n',\n",
    "#             'substandard': 'substd_n',\n",
    "#             'decline': 'decline_n'\n",
    "#             })\n",
    "#         .to_dict()\n",
    "#     )\n",
    "    \n",
    "#     for cls in['std','substd','decline']:\n",
    "#         d[f\"{cls}_prop\"] = d[f\"{cls}_n\"]/d['n']\n",
    "    \n",
    "#     d['nonstd_prop'] = (d['substd_n'] + d['decline_n'])/d['n']\n",
    "    \n",
    "    \n",
    "#     d['lr'] = df.tot_pay_amt.sum()/df.eff_annual_prem.sum() if len(df) > 0 and df.eff_annual_prem.sum() != 0 else 0\n",
    "#     # d['lr'] = df.tot_pay_amt.sum()/df.eff_annual_prem.sum()\n",
    "    \n",
    "    \n",
    "#     # for these two classes, also calculate their precision (i.e., agreement rate)\n",
    "#     if class_name == 'P_S':\n",
    "#         d['precision'] = df.risk_class.eq('standard').mean()\n",
    "#     elif class_name == 'M_N':\n",
    "#         # d['precision'] = df.risk_class.ne('standard').mean()\n",
    "#         d['precision'] = df.risk_class.isin(['substandard','decline']).mean()\n",
    "#     else:\n",
    "#         d['precision'] = np.nan\n",
    "        \n",
    "#     return pd.Series(d, name=class_name)\n",
    "\n",
    "# def find_pct_diff_lr(s1:pd.Series, s2:pd.Series, index_name='lr'):\n",
    "#     # return (s1[index_name]-s2[index_name])/(s2[index_name])*100\n",
    "#     return (s1[index_name]-s2[index_name])/(s2[index_name])\n",
    "\n",
    "# # find_stats(lr_out_test, \"prefer\", len(lr_out_test))\n",
    "# find_stats(lr_out_test, \"M_N\", len(lr_out_test))\n",
    "\n",
    "\n",
    "# # prop                1.00000\n",
    "# # n               26711.00000\n",
    "# # std_n           24008.00000\n",
    "# # substd_n         2073.00000\n",
    "# # decline_n         630.00000\n",
    "# # std_prop            0.89881\n",
    "# # substd_prop         0.07761\n",
    "# # decline_prop        0.02359\n",
    "# # nonstd_prop         0.10119\n",
    "# # lr                  0.59039\n",
    "# # precision           0.10119\n",
    "# # Name: M_N, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fdf730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_stats(df, class_name, total_size):\n",
    "#     d = {}\n",
    "#     d['prop'] = len(df)/total_size\n",
    "#     d['n'] = len(df)\n",
    "#     d.update(\n",
    "#         df\n",
    "#         .risk_class\n",
    "#         .value_counts(normalize=False)\n",
    "#         .rename({\n",
    "#             'standard': 'std_n',\n",
    "#             'substandard': 'substd_n',\n",
    "#             'decline': 'decline_n'\n",
    "#             })\n",
    "#         .to_dict()\n",
    "#     )\n",
    "    \n",
    "#     for cls in['std','substd','decline']:\n",
    "#         d[f\"{cls}_prop\"] = d[f\"{cls}_n\"]/d['n']\n",
    "    \n",
    "#     d['nonstd_prop'] = (d['substd_n'] + d['decline_n'])/d['n']\n",
    "    \n",
    "    \n",
    "#     d['lr'] = df.tot_pay_amt.sum()/df.eff_annual_prem.sum() if len(df) > 0 else 0\n",
    "#     # d['lr'] = df.tot_pay_amt.sum()/df.eff_annual_prem.sum()\n",
    "    \n",
    "#     # for these two classes, also calculate their precision (i.e., agreement rate)\n",
    "#     if class_name == 'P_S':\n",
    "#         d['precision'] = df.risk_class.eq('standard').mean()\n",
    "#     elif class_name == 'M_N':\n",
    "#         # d['precision'] = df.risk_class.ne('standard').mean()\n",
    "#         d['precision'] = df.risk_class.isin(['substandard','decline']).mean()\n",
    "    \n",
    "    \n",
    "#     # lr_cohort = df.groupby(cohort_col).apply(lambda gp: gp.tot_pay_amt.sum()/gp.eff_annual_prem.sum() if len(gp) > 0 else 0)\n",
    "    \n",
    "#     lr_cohort = (\n",
    "#         df\n",
    "#         .groupby(cohort_col)\n",
    "#         .apply(lambda gp: gp.tot_pay_amt.sum()/gp.eff_annual_prem.sum() if len(gp) > 0 and gp.eff_annual_prem.sum() != 0 else 0)\n",
    "#         .reset_index()\n",
    "#     )\n",
    "    \n",
    "#     lr_cohort = (\n",
    "#         lr_cohort\n",
    "#         .set_index('lr_' + lr_cohort['age_gp'].astype('str') + '_' + lr_cohort['sex_male'].replace({0:'M', 1:'F'}))\n",
    "#         .drop(['age_gp','sex_male'], axis=1)\n",
    "#         .squeeze()\n",
    "#     )\n",
    "    \n",
    "#     prop_cohort = df.groupby(cohort_col).size().div(len(df)).reset_index()\n",
    "    \n",
    "#     prop_cohort = (\n",
    "#     prop_cohort\n",
    "#     .set_index('prop_' + prop_cohort['age_gp'].astype('str') + '_' + prop_cohort['sex_male'].replace({0:'M', 1:'F'}))\n",
    "#     .drop(['age_gp','sex_male'], axis=1)\n",
    "#     .squeeze()\n",
    "# )\n",
    "    \n",
    "#     decline_prop_cohort = df.groupby(cohort_col).apply(lambda g: len(g.query(\"risk_class=='decline'\"))/len(g)).reset_index()\n",
    "    \n",
    "#     decline_prop_cohort = (\n",
    "#     decline_prop_cohort\n",
    "#     .set_index('decline_prop_' + decline_prop_cohort['age_gp'].astype('str') + '_' + decline_prop_cohort['sex_male'].replace({0:'M', 1:'F'}))\n",
    "#     .drop(['age_gp','sex_male'], axis=1)\n",
    "#     .squeeze()\n",
    "# )\n",
    "    \n",
    "#     # return pd.Series(d, name=class_name), lr_cohort\n",
    "#     return pd.concat([pd.Series(d), lr_cohort, prop_cohort, decline_prop_cohort], axis=0).rename(class_name)\n",
    "\n",
    "# def find_pct_diff_lr(s1:pd.Series, s2:pd.Series, index_name='lr'):\n",
    "#     # return (s1[index_name]-s2[index_name])/(s2[index_name])*100\n",
    "#     return (s1[index_name]-s2[index_name])/(s2[index_name])\n",
    "\n",
    "# def find_pct_diff_lr_plus(s1:pd.Series, s2:pd.Series):\n",
    "#     s1_trim = s1[s1.index.str.startswith('lr')]\n",
    "#     s2_trim = s2[s2.index.str.startswith('lr')]\n",
    "#     return ((s1_trim-s2_trim)/s2_trim).add_prefix(f\"prop_diff_{s1_trim.name}_{s2_trim.name}_\")\n",
    "\n",
    "# # find_stats(lr_out_test, \"prefer\", len(lr_out_test))\n",
    "# find_stats(lr_out_test, \"M_N\", len(lr_out_test))\n",
    "# # find_stats(lr_out_train, \"prefer\", len(lr_out_train))\n",
    "\n",
    "# # prop                1.00000\n",
    "# # n               26711.00000\n",
    "# # std_n           24008.00000\n",
    "# # substd_n         2073.00000\n",
    "# # decline_n         630.00000\n",
    "# # std_prop            0.89881\n",
    "# # substd_prop         0.07761\n",
    "# # decline_prop        0.02359\n",
    "# # nonstd_prop         0.10119\n",
    "# # lr                  0.59039\n",
    "# # precision           0.10119\n",
    "# # Name: M_N, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb7a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_out.groupby(cohort_col).risk_class.value_counts(normalize=True)\n",
    "# lr_out.groupby(cohort_col).apply(lambda g: len(g.query(\"risk_class=='decline'\"))/len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc4d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1 = find_stats(lr_out_test, \"M_N\", len(lr_out_test))\n",
    "# s2 = find_stats(lr_out_train, \"prefer\", len(lr_out_train))\n",
    "# s1\n",
    "# s2\n",
    "# # ((s1-s2)/s2).add_prefix(f\"prop_diff_{s1.name}_{s2.name}_\")\n",
    "\n",
    "# find_pct_diff_lr_plus(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b43bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1 = find_stats(lr_out_test, \"M_N\", len(lr_out_test))\n",
    "# s1[s1.index.str.startswith('lr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65022d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_gp = lr_out.groupby(cohort_col).apply(lambda gp: gp.tot_pay_amt.sum()/gp.eff_annual_prem.sum() if len(gp) > 0 else 0).reset_index()\n",
    "# lr_gp = lr_gp.set_index('lr_' + lr_gp['age_gp'].astype('str') + '_' + lr_gp['sex_male'].replace({0:'M', 1:'F'})).drop(['age_gp','sex_male'], axis=1).squeeze()\n",
    "# lr_gp\n",
    "\n",
    "# pd.concat([lr_gp,lr_gp], axis=0)\n",
    "\n",
    "# lr_gp = lr_out.groupby(cohort_col).apply(lambda gp: gp.tot_pay_amt.sum()/gp.eff_annual_prem.sum() if len(gp) > 0 else 0)\n",
    "# lr_gp.index\n",
    "# lr_gp.index.map('_'.join)\n",
    "# lr_gp.index.map(lambda s: str(s))\n",
    "\n",
    "# lr_gp.index.astype(str).agg('|'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822dcebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res.columns\n",
    "# df_res.loc[:, 'misc']\n",
    "# df_res[:1]\n",
    "# df_res.loc[:, (slice(None), ['prop','pref_bin','std_bin','margin_bin'])]\n",
    "# df_res \n",
    "# df_res.iloc[99:100]\n",
    "\n",
    "\n",
    "# for col in df_res.columns.values:\n",
    "#     '_'.join(s for s in col if s).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful_cols = [\n",
    "# 'contract_no',\n",
    "# 'annual_prem',\n",
    "# 'adj_annual_prem',\n",
    "# 'exposure',\n",
    "# 'year_seq',\n",
    "# 'tot_pay_amt',\n",
    "# 'inflate_tot_pay_amt']\n",
    "\n",
    "# columns = ', '.join(useful_cols) if useful_cols else '*'\n",
    "# with dsar.psql_con(\"WRITE\") as con:\n",
    "#     df = pd.read_sql(sql=f\"\"\"select {columns} from {lr_model_table}\n",
    "#                             where risk_class!='decline' and year_seq<=5 \"\"\", con = con)\n",
    "\n",
    "# # df = df[df.year_seq<=5]\n",
    "# df_lr_mapping = combine_records(df, use_adj_premium=use_adj_premium, use_inflate=use_inflate)\n",
    "# # df_lr_mapping = df_lr_mapping[df_lr_mapping.exposure==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema, table = tables['lr_out']\n",
    "# with dsar.psql_con('WRITE') as con:\n",
    "#     lr_out = pd.read_sql(f'''select out.*, sp.train_1, raw.risk_class\n",
    "#                             from {schema}.{table} out\n",
    "#                             inner join temp.hb_poc_splits sp\n",
    "#                             on sp.contract_no=out.contract_no\n",
    "#                             left join {decision_model_table} dm\n",
    "#                             on dm.contract_no = out.contract_no\n",
    "#                             left join \n",
    "#                                 (select distinct contract_no, risk_class from {lr_model_table}\n",
    "#                                 where risk_class is not null and year_seq=5) raw\n",
    "#                             on raw.contract_no = out.contract_no\n",
    "#                             ''', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age_gp_interval = list(range(0, 56, 5)) + [np.inf]\n",
    "\n",
    "# lr_out = (\n",
    "#     lr_out\n",
    "#     .query(\"risk_class == 'decline' or exposure==5 \")\n",
    "#     .assign(age_gp=lambda lr_out: pd.cut(lr_out['app_age'], age_gp_interval, right=True, include_lowest=True))\n",
    "#     .merge(df_lr_mapping[['contract_no','loss_ratio','tot_pay_amt', 'eff_annual_prem']], how='left', on='contract_no')\n",
    "# )\n",
    "# lr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_out = lr_out.replace({\n",
    "#     'risk_class': {\n",
    "#         'exclusion':'substandard', \n",
    "#         'exclusion_loading':'substandard', \n",
    "#         'loading':'substandard'\n",
    "#         },\n",
    "#             })\n",
    "# lr_out_test = lr_out.query(\"train_1==0\").copy()\n",
    "# lr_out_train = lr_out.query(\"train_1==1\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_out_test.bin_dlr\n",
    "\n",
    "# lr_out_test.bin_dlr.value_counts()\n",
    "\n",
    "# lr_out_test\n",
    "# sns.relplot(data=lr_out_test, x='bin_dlr', y='bmi', kind='line', ci=None)\n",
    "\n",
    "# sns.relplot(data='lr_out_test', x='bmi', y='bmi', kind='line')\n",
    "# lr_out_test\n",
    "# lr_out_test.groupby('bin_dlr').bmi.mean().plot()\n",
    "\n",
    "# sns.relplot(data=lr_out_test.query(\"diff_high >0\"), x='bin_dlr', y='bmi', kind='line', row='age_gp', col='sex_male', ci=None)\n",
    "\n",
    "\n",
    "# g = sns.relplot(data=lr_out_test.query(\"clean_record==0\"), x='bin_dlr', y='bmi', kind='line', row='age_gp', col='sex_male', ci=None, facet_kws={'sharex':False})\n",
    "\n",
    "\n",
    "# sns.relplot(data=lr_out_test, x='bin_dlr', y='bmi', kind='line', row='age_gp', col='sex_male', ci=None, facet_kws={'sharex':False})\n",
    "# sns.relplot(data=lr_out_test, x='bin_dlr', y='bmi', kind='scatter', row='age_gp', col='sex_male', ci=None)\n",
    "\n",
    "\n",
    "\n",
    "# g = sns.relplot(data=lr_out_test, x='bin_dlr', y='bmi', kind='line', row='age_gp', col='sex_male', ci=None, facet_kws={'sharex':False})\n",
    "# for ax in g.axes.flat:\n",
    "#     _ = ax.set_xlabel('bin')\n",
    "# g.tight_layout()\n",
    "\n",
    "# plt.figure()\n",
    "# sns.histplot(data=lr_out_test.query(\"diff_high>0\"), x='bin_dlr', bins=20).set(title='bin distribution for those with diff_high>0')\n",
    "\n",
    "# lr_out_test.query(\"diff_high>0\").bin_dlr.plot.hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ae74f9feb07f97b665e59d852dca9947bf3c6be9bdf551f43d711a8fd00af3ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
